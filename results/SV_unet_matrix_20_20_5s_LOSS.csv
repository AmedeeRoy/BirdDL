step_loss_train,step_loss_validation
0.8725327030086601,0.9524269661942466
0.8375353585456459,0.9150653884059093
0.8010784975764617,0.8655041016516138
0.779224246189418,0.8548042047219199
0.7390429280488424,0.8216679744056014
0.7346959493162346,0.815838987710046
0.7271876559973183,0.8273999134048087
0.7053897404439853,0.7910836508039568
0.6950175157210357,0.7750132637922881
0.6841131495180685,0.7675710753339235
0.6807569968186213,0.7677594859091962
0.6793600870427531,0.7640159486747179
0.6767335313726479,0.7643800699319996
0.6754162613774689,0.7619051385121267
0.674211584634974,0.7641971725909437
0.6721605006605387,0.7600398498480437
0.6711493839417965,0.7603506875819848
0.6697721166509978,0.7582982321254542
0.669097253501835,0.7581346986723728
0.6709959262221212,0.7590218745294165
0.6695275910880784,0.7590327956637398
0.6683715348669761,0.759489964364005
0.6695707544002315,0.757629242197412
0.6687864276619864,0.7595781777725845
0.6692195827220108,0.7575764231017379
0.6677779776477059,0.757269230045256
0.6703312650427852,0.7563870611737986
0.6675079820126715,0.757989907362422
0.6679596039400973,0.7568668977158969
0.6687255480234892,0.7570893893476393
0.6698895469832589,0.7568498841074647
0.6689364515822118,0.7601042295088534
0.6678776014858568,0.7574039631202573
0.6673563291174425,0.7573804807467539
0.668799308666461,0.7570165949766753
