{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SV_unet_projection_guanape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNd0M5QWYT1Ieaqb1SxC4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmedeeRoy/BirdDL/blob/main/code/SV/5s/SV_unet_projection_guanape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVau6SVYYqzD"
      },
      "source": [
        "# Test Guanape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPOjT66sGf3Y",
        "outputId": "93767126-499f-45d6-ca5f-6572507cb32c"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2R6nZsEGp2v",
        "outputId": "48417337-dba4-4a3b-ba18-264beda6e9b8"
      },
      "source": [
        "%cd drive/My\\ Drive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGN6h34CFYo0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "from utils.trip import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGjbuWmXFgTp"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxj5AbApGG2w"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.threshold = nn.Sequential(\n",
        "#             nn.BatchNorm2d(1),\n",
        "            nn.Conv2d(1, 8, kernel_size = 1, stride = 1, padding = 0, dilation = 1, bias = True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.cnn_input_1 = nn.Sequential(\n",
        "            nn.BatchNorm1d(8+3),\n",
        "            nn.Conv1d(8+3, 8, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(8, 8, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pooling_1 = nn.Sequential(\n",
        "            nn.MaxPool1d(kernel_size = 5, stride = 2, padding = 2, dilation = 1)\n",
        "        )\n",
        "\n",
        "        self.cnn_input_2 = nn.Sequential(\n",
        "            nn.BatchNorm1d(8),\n",
        "            nn.Conv1d(8, 16, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(16, 16, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pooling_2 = nn.Sequential(\n",
        "            nn.MaxPool1d(kernel_size = 5, stride = 2, padding = 2, dilation = 1)\n",
        "        )\n",
        "\n",
        "        self.cnn_input_3 = nn.Sequential(\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.Conv1d(16, 32,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 32,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.upconv_2 = nn.Sequential(\n",
        "             nn.ConvTranspose1d(32, 16, kernel_size = 6, stride = 2, padding = 2, dilation = 1)\n",
        "         )\n",
        "\n",
        "        self.cnn_output_2 = nn.Sequential(\n",
        "            nn.BatchNorm1d(16*2),\n",
        "            nn.Conv1d(16*2, 16,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(16, 16,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.upconv_1 = nn.Sequential(\n",
        "             nn.ConvTranspose1d(16, 8, kernel_size = 6, stride = 2, padding = 2, dilation = 1)\n",
        "         )\n",
        "        \n",
        "        self.cnn_output_1 = nn.Sequential(\n",
        "            nn.BatchNorm1d(8*2),\n",
        "            nn.Conv1d(8*2, 8,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(8, 4, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(4, 2, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(2, 1,  kernel_size = 5, stride = 1, padding = 2, dilation = 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        out = self.threshold(y)\n",
        "        out = torch.sum(out, 2)\n",
        "\n",
        "        out = torch.cat((out, x.squeeze(1)), 1)\n",
        "\n",
        "        out_1 = self.cnn_input_1(out)\n",
        "        out = self.pooling_1(out_1)\n",
        "        out_2 = self.cnn_input_2(out)\n",
        "        out = self.pooling_2(out_2)\n",
        "        out = self.cnn_input_3(out)\n",
        "\n",
        "        out = self.upconv_2(out)\n",
        "        out = torch.cat((out, out_2), 1)\n",
        "        out = self.cnn_output_2(out)\n",
        "\n",
        "        out = self.upconv_1(out)\n",
        "        out = torch.cat((out, out_1), 1)\n",
        "        out = self.cnn_output_1(out)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "def get_score(out, y):\n",
        "    out, y = out.cpu(), y.cpu()\n",
        "    out = 1*(out>0)\n",
        "    true_positive = np.mean(out[y == True].numpy()) \n",
        "    true_negative = 1-np.mean(out[y == False].numpy())\n",
        "    \n",
        "    return (round(true_positive*100) , round(true_negative*100))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9Wwa1HFf5h"
      },
      "source": [
        "model = torch.load('SV_unet_matrixlonlatcov_5s.pt')\n",
        "window = 20\n",
        "variable = ('lon_std', 'lat_std', 'gaps')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yxwg5K0O3lj"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eno4VDnsNX_r"
      },
      "source": [
        "# # select only two trips\n",
        "\n",
        "# train_trajs = data_test_new.trip.unique()[0:5]\n",
        "# data_train_new = data_test_new[data_test_new.trip.isin(train_trajs)]\n",
        "\n",
        "# validation_trajs = data_test_new.trip.unique()[5:len(data_test_new.trip.unique())]\n",
        "# data_validation_new = data_test_new[data_test_new.trip.isin(validation_trajs)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS9J_w8-NDun"
      },
      "source": [
        "# # hyperparameters\n",
        "# batch_size = 64\n",
        "\n",
        "# ## reduce size dataset\n",
        "# train_set = TrajDataSet(data_train_new, window, variable, transform = ToTensor())\n",
        "# validation_set = TrajDataSet(data_validation_new, window, variable, transform = ToTensor())\n",
        "\n",
        "# train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=True)\n",
        "# validation_loader = DataLoader(validation_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uys5uKXMPAWi"
      },
      "source": [
        "# # Loss and score\n",
        "# learning_rate = 0.01\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# weight = torch.FloatTensor([30])\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight = weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s3_4KluPMeU"
      },
      "source": [
        "# # Train the model\n",
        "# nb_epoch = 5\n",
        "    \n",
        "# for epoch in range(nb_epoch):\n",
        "#     learning_rate /= 10\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#     for batch, (x, y, z) in enumerate(train_loader):\n",
        "\n",
        "#         # Run the forward pass\n",
        "#         out = model(x, y)\n",
        "#         loss = criterion(out, z)\n",
        "        \n",
        "#         # Backprop and perform optimisation\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     ### Evaluation\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():     \n",
        "#         # evaluation\n",
        "#         list_loss_train = []\n",
        "#         list_score_train = []\n",
        "#         for batch, (x, y, z) in enumerate(train_loader):\n",
        "\n",
        "#             # Run the forward pass\n",
        "#             out =  model(x, y)\n",
        "#             loss = criterion(out, z)\n",
        "\n",
        "#             list_loss_train.append(loss.item())\n",
        "            \n",
        "#         train_loss = np.mean(list_loss_train)\n",
        "       \n",
        "\n",
        "#     print('Epoch [{}/{}] -------------------------------------------------------------------------------------'\n",
        "#       .format(epoch+1, nb_epoch))\n",
        "#     print('Train Loss: {}'\n",
        "#             .format(round(train_loss, 2)))\n",
        "#     model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-coP1OmO8Ct"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Jvl0wKeq_L"
      },
      "source": [
        "data_train = pd.read_csv('./data/SV_train.csv')\n",
        "data_validation = pd.read_csv('./data/SV_validation.csv')\n",
        "data_test = pd.read_csv('./data/SV_test.csv')\n",
        "data_test_guanape = pd.read_csv('./data/SV_test_guanape.csv')\n",
        "\n",
        "data = pd.concat([data_train, data_validation, data_test, data_test_guanape])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nZ_4Oy5Ud5mn",
        "outputId": "98634d6a-897f-4fb8-b151-a9c35e92bfc2"
      },
      "source": [
        "resolution = 5\n",
        "data_new = change_resolution(data, resolution)\n",
        "data_new = standardize_data(data_new)\n",
        "\n",
        "data_new.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trip</th>\n",
              "      <th>datetime</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "      <th>gaps</th>\n",
              "      <th>dive</th>\n",
              "      <th>step_speed</th>\n",
              "      <th>step_direction</th>\n",
              "      <th>lon_std</th>\n",
              "      <th>lat_std</th>\n",
              "      <th>step_speed_std</th>\n",
              "      <th>step_direction_cos</th>\n",
              "      <th>step_direction_sin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P1108_46_SV_T4</td>\n",
              "      <td>2008-12-06 16:06:25</td>\n",
              "      <td>-77.265897</td>\n",
              "      <td>-11.774297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.301035</td>\n",
              "      <td>26.025648</td>\n",
              "      <td>2.309584</td>\n",
              "      <td>0.788287</td>\n",
              "      <td>0.826924</td>\n",
              "      <td>0.898598</td>\n",
              "      <td>0.438773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P1108_46_SV_T4</td>\n",
              "      <td>2008-12-06 16:06:30</td>\n",
              "      <td>-77.266435</td>\n",
              "      <td>-11.774462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.287117</td>\n",
              "      <td>-18.228550</td>\n",
              "      <td>2.293957</td>\n",
              "      <td>0.776022</td>\n",
              "      <td>0.663327</td>\n",
              "      <td>0.949816</td>\n",
              "      <td>-0.312808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P1108_46_SV_T4</td>\n",
              "      <td>2008-12-06 16:06:35</td>\n",
              "      <td>-77.266843</td>\n",
              "      <td>-11.774868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.679214</td>\n",
              "      <td>-28.073536</td>\n",
              "      <td>2.282105</td>\n",
              "      <td>0.745841</td>\n",
              "      <td>0.684610</td>\n",
              "      <td>0.882344</td>\n",
              "      <td>-0.470604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>P1108_46_SV_T4</td>\n",
              "      <td>2008-12-06 16:06:40</td>\n",
              "      <td>-77.267200</td>\n",
              "      <td>-11.775312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.579325</td>\n",
              "      <td>-6.324066</td>\n",
              "      <td>2.271735</td>\n",
              "      <td>0.712835</td>\n",
              "      <td>0.679188</td>\n",
              "      <td>0.993915</td>\n",
              "      <td>-0.110152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>P1108_46_SV_T4</td>\n",
              "      <td>2008-12-06 16:06:45</td>\n",
              "      <td>-77.267390</td>\n",
              "      <td>-11.775845</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.567659</td>\n",
              "      <td>-18.969971</td>\n",
              "      <td>2.266216</td>\n",
              "      <td>0.673214</td>\n",
              "      <td>0.678555</td>\n",
              "      <td>0.945689</td>\n",
              "      <td>-0.325073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             trip             datetime  ...  step_direction_cos  step_direction_sin\n",
              "2  P1108_46_SV_T4  2008-12-06 16:06:25  ...            0.898598            0.438773\n",
              "3  P1108_46_SV_T4  2008-12-06 16:06:30  ...            0.949816           -0.312808\n",
              "4  P1108_46_SV_T4  2008-12-06 16:06:35  ...            0.882344           -0.470604\n",
              "5  P1108_46_SV_T4  2008-12-06 16:06:40  ...            0.993915           -0.110152\n",
              "6  P1108_46_SV_T4  2008-12-06 16:06:45  ...            0.945689           -0.325073\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pSGmDuF9YqzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46a625f-1233-4856-bd4b-bdb6604563fd"
      },
      "source": [
        "dive_estim = []\n",
        "\n",
        "for i in data_new.trip.unique():\n",
        "    # create dataset for a trajectory\n",
        "    t = data_new[data_new.trip == i].copy()    \n",
        "    test_set = TrajDataSet(t, window, variable, transform = ToTensor())\n",
        "    \n",
        "    # Test the model\n",
        "    estim = np.zeros(len(t))\n",
        "    nb = np.zeros(len(t))\n",
        "    \n",
        "    list_out = []\n",
        "    model.eval()\n",
        "    k = 0\n",
        "    with torch.no_grad():\n",
        "        for (x, y, z) in test_set:\n",
        "\n",
        "            # Run the forward pass\n",
        "            out = model(x, y.unsqueeze(1))\n",
        "            \n",
        "            estim[k:k + round(window)] += out.cpu().squeeze().numpy()\n",
        "            nb[k:k + round(window)] += 1\n",
        "            k+=1\n",
        "    # # add to list by trajectory\n",
        "    dive_estim.append(estim/nb)\n",
        "    print(i)\n",
        "\n",
        "data_new['prediction'] = 1/(1+np.exp(-np.hstack(dive_estim)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P1108_46_SV_T4\n",
            "P1108_4_SV_T1\n",
            "P1108_4_SV_T2\n",
            "P1108_6_SV_T1\n",
            "P1109_21_SV_T4\n",
            "P1109_21_SV_T7\n",
            "P1111_27_SV_T2\n",
            "P1111_27_SV_T4\n",
            "P1111_41_SV_T1\n",
            "P1111_41_SV_T4\n",
            "P1111_46_SV_T5\n",
            "P1111_9_SV_T2\n",
            "P1112_10_SV_T1\n",
            "P1112_11_SV_T7\n",
            "P1112_12_SV_T1\n",
            "P1112_12_SV_T4\n",
            "P1112_14_SV_T1\n",
            "P1112_14_SV_T2\n",
            "P1112_15_SV_T1\n",
            "P1112_15_SV_T2\n",
            "P1112_15_SV_T3\n",
            "P1112_15_SV_T4\n",
            "P1112_18_SV_T2\n",
            "P1112_18_SV_T3\n",
            "P1112_18_SV_T5\n",
            "P1112_19_SV_T2\n",
            "P1112_19_SV_T3\n",
            "P1112_19_SV_T4\n",
            "P1112_19_SV_T5\n",
            "P1112_19_SV_T6\n",
            "P1112_19_SV_T7\n",
            "P1112_20_SV_T1\n",
            "P1112_20_SV_T2\n",
            "P1112_20_SV_T3\n",
            "P1112_21_SV_T1\n",
            "P1112_21_SV_T2\n",
            "P1112_22_SV_T1\n",
            "P1112_22_SV_T2\n",
            "P1112_22_SV_T3\n",
            "P1112_24_SV_T1\n",
            "P1112_24_SV_T3\n",
            "P1112_24_SV_T4\n",
            "P1112_25_SV_T1\n",
            "P1112_25_SV_T3\n",
            "P1112_25_SV_T4\n",
            "P1112_25_SV_T5\n",
            "P1112_26_SV_T3\n",
            "P1112_27_SV_T1\n",
            "P1112_27_SV_T2\n",
            "P1112_29_SV_T2\n",
            "P1112_29_SV_T3\n",
            "P1112_30_SV_T1\n",
            "P1112_30_SV_T2\n",
            "P1112_31_SV_T1\n",
            "P1112_31_SV_T2\n",
            "P1112_31_SV_T5\n",
            "P1112_33_SV_T2\n",
            "P1112_34_SV_T1\n",
            "P1112_35_SV_T2\n",
            "P1112_37_SV_T1\n",
            "P1112_37_SV_T2\n",
            "P1112_37_SV_T3\n",
            "P1112_38_SV_T1\n",
            "P1112_38_SV_T2\n",
            "P1112_3_SV_T2\n",
            "P1112_4_SV_T2\n",
            "P1112_4_SV_T4\n",
            "P1112_9_SV_T1\n",
            "P1112_9_SV_T2\n",
            "P1113_15_SV_T1\n",
            "P1113_15_SV_T2\n",
            "P1113_18_SV_T1\n",
            "P1113_18_SV_T4\n",
            "P1113_19_SV_T1\n",
            "P1113_19_SV_T3\n",
            "P1113_23_SV_T1\n",
            "P1113_23_SV_T2\n",
            "P1113_23_SV_T3\n",
            "P1113_23_SV_T4\n",
            "P1113_24_SV_T1\n",
            "P1113_24_SV_T2\n",
            "P1113_24_SV_T3\n",
            "P1113_28_SV_T1\n",
            "P1113_28_SV_T2\n",
            "P1113_28_SV_T3\n",
            "P1113_29_SV_T1\n",
            "P1113_33_SV_T2\n",
            "P1113_33_SV_T3\n",
            "P1113_33_SV_T4\n",
            "P1113_41_SV_T1\n",
            "P1113_41_SV_T4\n",
            "P1113_41_SV_T5\n",
            "P1113_41_SV_T6\n",
            "P1108_46_SV_T2\n",
            "P1108_46_SV_T3\n",
            "P1109_21_SV_T1\n",
            "P1109_21_SV_T2\n",
            "P1109_21_SV_T3\n",
            "P1109_21_SV_T5\n",
            "P1109_21_SV_T8\n",
            "P1111_13_SV_T5\n",
            "P1111_52_SV_T2\n",
            "P1112_12_SV_T2\n",
            "P1112_12_SV_T3\n",
            "P1112_24_SV_T2\n",
            "P1112_24_SV_T5\n",
            "P1112_24_SV_T6\n",
            "P1112_25_SV_T2\n",
            "P1112_26_SV_T4\n",
            "P1112_33_SV_T1\n",
            "P1112_35_SV_T1\n",
            "P1112_35_SV_T3\n",
            "P1112_35_SV_T4\n",
            "P1112_36_SV_T1\n",
            "P1112_3_SV_T1\n",
            "P1112_4_SV_T1\n",
            "P1113_18_SV_T2\n",
            "P1113_18_SV_T3\n",
            "P1113_19_SV_T4\n",
            "P1113_29_SV_T2\n",
            "P1108_6_SV_T2\n",
            "P1111_41_SV_T3\n",
            "P1111_41_SV_T6\n",
            "P1112_10_SV_T2\n",
            "P1112_18_SV_T1\n",
            "P1112_20_SV_T4\n",
            "P1112_27_SV_T3\n",
            "P1112_29_SV_T1\n",
            "P1112_31_SV_T3\n",
            "P1113_14_SV_T1\n",
            "P1113_19_SV_T2\n",
            "P1113_33_SV_T1\n",
            "P1113_41_SV_T2\n",
            "G1107_12_SV_T1\n",
            "G1107_15_SV_T1\n",
            "G1107_17_SV_T1\n",
            "G1107_18_SV_T1\n",
            "G1107_18_SV_T2\n",
            "G1107_20_SV_T1\n",
            "G1107_21_SV_T1\n",
            "G1107_22_SV_T1\n",
            "G1107_24_SV_T1\n",
            "G1107_25_SV_T1\n",
            "G1107_26_SV_T1\n",
            "G1107_27_SV_T1\n",
            "G1107_27_SV_T2\n",
            "G1107_34_SV_T1\n",
            "G1107_34_SV_T2\n",
            "G1107_34_SV_T3\n",
            "G1107_36_SV_T1\n",
            "G1107_39_SV_T1\n",
            "G1107_42_SV_T2\n",
            "G1107_46_SV_T1\n",
            "G1107_49_SV_T2\n",
            "G1107_53_SV_T1\n",
            "G1107_7_SV_T1\n",
            "G1107_7_SV_T2\n",
            "G1107_9_SV_T1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORD6kHcxlA7I"
      },
      "source": [
        "data_test_new = data_new[[x[0] == 'G' for x in data_new.trip]]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tklMINGYqzF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "57952582-826f-492e-8729-d9a8dad6198b"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.set_aspect('equal')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "\n",
        "\n",
        "# globally\n",
        "TP = []\n",
        "FP = []\n",
        "\n",
        "for tt in np.arange(0,1,0.001):\n",
        "    all_estim = 1* (data_test_new.prediction > tt)\n",
        "    true_positive = np.mean(all_estim[data_test_new.dive == 1])\n",
        "    true_negative = 1-np.mean(all_estim[data_test_new.dive == 0])\n",
        "    TP.append(true_positive)\n",
        "    FP.append(1-true_negative)\n",
        "\n",
        "plt.plot(np.array(FP), np.array(TP))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f149ff08048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbMfbZ4IBAz"
      },
      "source": [
        "# Export Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfJ0qe7IIAaU"
      },
      "source": [
        "data_new.to_csv('SV_unet_projection.csv', index = False)"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}