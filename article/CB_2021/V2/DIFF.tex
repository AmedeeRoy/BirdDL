\documentclass{article}
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL ORIGINAL.tex   Mon Apr 19 12:13:40 2021
%DIF ADD REVISION.tex   Mon Nov 15 18:14:12 2021

\usepackage{arxiv}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{gensymb}
\usepackage{lineno}
\usepackage{setspace}

%DIF 18-19c18-19
%DIF < \usepackage{biblatex}
%DIF < \addbibresource{DeepDive.bib}
%DIF -------
\usepackage[style=ieee]{biblatex} %DIF >
\addbibresource{library.bib} %DIF >
%DIF -------

\title{Deep \DIFdelbegin \DIFdel{learning and Trajectory Representation for the Prediction of Seabird Diving Behaviour}\DIFdelend \DIFaddbegin \DIFadd{inference of seabird dives from GPS-only records: performance and generalization properties}\DIFaddend }
%DIF 22d22
%DIF <
%DIF -------

\author{
  Amédée Roy \\
  Institut de Recherche pour le Développement (IRD),\\
  MARBEC (Univ. Montpellier, Ifremer, CNRS, IRD)\\
  Avenue Jean Monnet, 34200, Sète, France \\
  \texttt{amedee.roy@ird.fr} \\
   \And
  Sophie \DIFdelbegin \DIFdel{Lanco-Bertrand }\DIFdelend \DIFaddbegin \DIFadd{Lanco Bertrand }\DIFaddend \\
  Institut de Recherche pour le Développement (IRD),\\
  MARBEC (Univ. Montpellier, Ifremer, CNRS, IRD)\\
  Avenue Jean Monnet, 34200, Sète, France \\
  \texttt{sophie.bertrand@ird.fr} \\
  \And
  Ronan Fablet \\
  IMT Atlantique,\\
  UMR CNRS Lab-STICC\\
  Brest, France \\
  \texttt{ronan.fablet@imt-atlantique.fr} \\
}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF LISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}

\maketitle
\linenumbers
\doublespacing

\begin{abstract}
\DIFdelbegin \DIFdel{Seabirds are considered as suitable indicators for the study of marine ecosystems, since their foraging strategies provide a real-time response to complex ecosystem dynamics . By deploying GPS sensors onseabirds it is  possible to obtain their trajectories , and deep learning have recently }\DIFdelend \DIFaddbegin \DIFadd{At-sea behaviour of seabirds have received significant attention in ecology over the last decades as it is a key process in the ecology and fate of these populations. It is also, through the position of top predator that these species often occupy, a relevant and integrative indicator of the dynamics of the marine ecosystems they rely on. Seabird trajectories are recorded through the deployment of GPS, and a variety of statistical approaches have been tested to infer probable behaviours from these location data. Recently, deep learning tools have }\DIFaddend shown promising results for the \DIFaddbegin \DIFadd{segmentation and }\DIFaddend classification of animal behaviour from trajectory data. Yet\DIFdelbegin \DIFdel{there is still lot of investigation needed in terms of network architectures, data representation but also to demonstrate the generalization propertiesof these approaches}\DIFdelend \DIFaddbegin \DIFadd{, these approaches have not been widely used and  investigation is still needed to identify optimal network architecture and to demonstrate their generalization properties}\DIFaddend . From a database of about \DIFdelbegin \DIFdel{250 }\DIFdelend \DIFaddbegin \DIFadd{300 }\DIFaddend foraging trajectories derived from GPS data deployed simultaneously with pressure sensors for the identification of dives, this work has \DIFdelbegin \DIFdel{consisted in training deep networks }\DIFdelend \DIFaddbegin \DIFadd{benchmarked deep neural network architectures trained }\DIFaddend in a supervised manner for the prediction of dives from trajectory data. \DIFdelbegin \DIFdel{In this study, we confirm }\DIFdelend \DIFaddbegin \DIFadd{It first confirms }\DIFaddend that deep learning allows better dive prediction than usual methods such as Hidden Markov Models\DIFdelbegin \DIFdel{for two distinct seabirds species. We propose a novel deep learning model for trajectory data. It combines the computational efficiency of convolutional neural networks to distance-matrix-based representations of trajectory data. Our model considerably increases the ability of deep networks to infer behaviours, as well as their stability to different data inputs. The considered trajectory data representation might enable deep networks to better capture spatial information than from longitude and latitude time-series considered in previous works }\DIFdelend . \DIFaddbegin \DIFadd{It also demonstrates the generalization properties of the trained networks for inferring dives distribution for seabirds from other colonies and ecosystems. In particular, convolutional networks trained on Peruvian boobies from a specific colony show great ability to predict dives of boobies from other colonies and from distinct ecosystems. We further investigate accross-species generalization using a transfer learning strategy known as 'fine-tuning'. Starting from a convolutional network pre-trained on Guanay cormorant data reduced by two the size of the dataset needed to accurately predict dives in a tropical booby from Brazil. We believe that the networks trained in this study will provide relevant starting point for future fine-tuning works for seabird trajectory segmentation.
}\DIFaddend \end{abstract}

% keywords can be removed
\DIFdelbegin %DIFDELCMD < \keywords{machine learning \and neural network \and distance matrix \and Peruvian booby \and Guanay cormorant \and diving behaviour}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \keywords{deep learning \and neural network \and transfer learning \and Peruvian booby \and Guanay cormorant \and Masked booby}
\DIFaddend

\newpage

\section{Introduction}
Marine \DIFdelbegin \DIFdel{megafauna (i.e. species that depend on marine resources for their food and located at the top of the trophic food webs) }\DIFdelend \DIFaddbegin \DIFadd{top predators }\DIFaddend have received significant attention in marine ecology over the last decades \cite{authier_conservation_2017}. \DIFdelbegin \DIFdel{These species }\DIFdelend \DIFaddbegin \DIFadd{They }\DIFaddend are known to use vast areas for feeding, thus requiring specific adaptive foraging strategies in order to localize their preys, especially in the pelagic environments which are highly variable. \cite{hazen_marine_2019}. They offer a unique perspective into ocean processes and dynamics, given that they can amplify information on the structure of the seascape across multiple \DIFdelbegin \DIFdel{spatiotemporal }\DIFdelend \DIFaddbegin \DIFadd{spatio-temporal }\DIFaddend scales due to their relatively high mobility and longevity. Often considered as sentinels of the environmental variability and bio-indicators for ecosystem structure and dynamics, their study has been particularly contextualized into ecosystem-based management and conservation issues \cite{lascelles_migratory_2014, hooker_marine_2004}.

\DIFdelbegin \DIFdel{Among marine megafauna species, seabird are considered as suitable indicators because they are both sensitive to variations in food supply and relatively easy to observe \mbox{%DIFAUXCMD
\cite{furness_seabirds_1997, wakefield_quantifying_2009}}\hspace{0pt}%DIFAUXCMD
.
During breeding season, seabird must return regularly on land to brood and feed chicks between foraging trips.
Feeding at sea while breeding at land (i.e. central place foraging) implies  that seabirdshad to develop specific morphological, physiological and behavioural abilities in order to navigate efficiently to foraging zones eventually far from the breeding site, to capture preys and to go back to the nest in relatively short times \mbox{%DIFAUXCMD
\cite{schreiber_biology_2001}}\hspace{0pt}%DIFAUXCMD
. At this period seabirds have no constraints related to predator avoidance, partner or site selection, foraging trips are thus essentially dedicated to food acquisition. For these reasons, their foraging movements have been suggested to reflect prey abundance and distribution at sea \mbox{%DIFAUXCMD
\cite{weimerskirch_are_2007}}\hspace{0pt}%DIFAUXCMD
.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdel{Over the last decades, the study of animal movements has been revolutionized }\DIFdelend \DIFaddbegin \DIFadd{Numerous studies have focused on the variability of seabirds' foraging strategies and in particular of dive distributions. Assessing consistency or shifts in foraging locations \mbox{%DIFAUXCMD
\cite{bost_large-scale_2015,meier_consistent_2015-1,oppel_seasonal_2017}}\hspace{0pt}%DIFAUXCMD
, and in the resource spatial partitioning  \mbox{%DIFAUXCMD
\cite{kappes_variability_2011,bolton_review_2019} }\hspace{0pt}%DIFAUXCMD
provide indeed crucial information for understanding marine ecosystems. This has been particularly enabled }\DIFaddend by great technical advances in the miniaturization and autonomy of \DIFdelbegin \DIFdel{devices \mbox{%DIFAUXCMD
\cite{ropert-coudert_diving_2009,monaco_bio-logging_2016}}\hspace{0pt}%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{biologging devices \mbox{%DIFAUXCMD
\cite{ropert-coudert_diving_2009,chung_review_2021}}\hspace{0pt}%DIFAUXCMD
}\DIFaddend . GPS loggers have been at the forefront of this breakthrough, and can now provide precise and accurate data on the \DIFdelbegin \DIFdel{movements }\DIFdelend \DIFaddbegin \DIFadd{foraging trajectories }\DIFaddend of many free-ranging species, such as seabirds \cite{wakefield_quantifying_2009,yoda_advances_2019}. \DIFdelbegin \DIFdel{The derived data is particularly useful in studying a variety of behavioral aspects including habitat selection, migration or dispersion patterns, and foraging
strategies \mbox{%DIFAUXCMD
\cite{nathan_movement_2008}}\hspace{0pt}%DIFAUXCMD
.
}\DIFdelend Detailed information on the \DIFdelbegin \DIFdel{foraging behaviour has }\DIFdelend \DIFaddbegin \DIFadd{diving behaviour has also }\DIFaddend been gained through the \DIFdelbegin \DIFdel{combined use of GPS and }\DIFdelend \DIFaddbegin \DIFadd{additional use of pressure sensors, such as }\DIFaddend Time Depth Recorders (TDR) devices \DIFdelbegin \DIFdel{.
TDR devices capture dive profiles of marine animals and many studies have used pressure as a proxy to seabirds' foraging behaviour \mbox{%DIFAUXCMD
\cite{cox_seabird_2016,lewis_flexible_2004,shoji_foraging_2015}}\hspace{0pt}%DIFAUXCMD
. }%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{cox_seabird_2016,lewis_flexible_2004,shoji_foraging_2015}}\hspace{0pt}%DIFAUXCMD
. }\DIFaddend Yet, for \DIFdelbegin \DIFdel{practical}\DIFdelend \DIFaddbegin \DIFadd{historical}\DIFaddend , financial and ethical reasons, the deployment of several sensors \DIFdelbegin \DIFdel{is not always possible and efforts have been made to develop accurate methods to infer foraging locations from GPS data.
Many }\DIFdelend \DIFaddbegin \DIFadd{has not always been possible and a substantial amount of tracking datasets consist in GPS tracks only. The development of tools dedicated to animal trajectories segmentation (i.e. for dive identification) is therefore needed to extract more out of historical seabird foraging trajectories \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}}\hspace{0pt}%DIFAUXCMD
.
}

\DIFadd{Among existing approaches to dive identification from GPS tracks, many }\DIFaddend individual-based studies aim to infer behavioral state directly by applying thresholds \DIFdelbegin \DIFdel{from }\DIFdelend \DIFaddbegin \DIFadd{to }\DIFaddend various ecological metrics of movement data, such as speed, direction and tortuosity \cite{dean_simultaneous_2015,seidel_ecological_2018}. A common example is the so-called First-Passage Time \DIFdelbegin \DIFdel{(FPT) method}\DIFdelend \DIFaddbegin \DIFadd{method (hereafter, FPT)}\DIFaddend , which is defined as the time taken for an individual to cross a virtual circle of given radius \cite{carter_navigating_2016,pinaud_at-sea_2007,sommerfeld_foraging_2013}. Here foraging behaviour is assumed to occur when birds fly at very low speeds \cite{weimerskirch_foraging_2008}. \DIFdelbegin \DIFdel{Modelling }\DIFdelend \DIFaddbegin \DIFadd{Statistical }\DIFaddend methods have also been used to predict diving behaviour \DIFdelbegin \DIFdel{taking the sequence of trajectory data into account through }\DIFdelend \DIFaddbegin \DIFadd{with clustering schemes such as the Expectation Maximization binary clustering technique \mbox{%DIFAUXCMD
\cite{mendez_geographical_2017,garriga_expectation-maximization_2016} }\hspace{0pt}%DIFAUXCMD
or using }\DIFaddend hidden Markov models (\DIFaddbegin \DIFadd{hereafter, }\DIFaddend HMM) typically with 2 or 3 distinct behavioural modes \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
\cite{boyd_movement_2014,dunphy_seabirds_2020,mcclintock_momentuhmm_2018,oppel_foraging_2015}}\hspace{0pt}%DIFAUXCMD
, and more occasionallythrough gaussian mixtures models \mbox{%DIFAUXCMD
\cite{guilford_gps_2008,mendez_geographical_2017}}\hspace{0pt}%DIFAUXCMD
, or }\DIFdelend \DIFaddbegin \DIFadd{to explicit account for time-related priors \mbox{%DIFAUXCMD
\cite{boyd_movement_2014,dunphy_seabirds_2020,mcclintock_momentuhmm_2018,oppel_foraging_2015}}\hspace{0pt}%DIFAUXCMD
. More occasionally, }\DIFaddend supervised machine learning approaches such as artificial neural networks, support vector \DIFdelbegin \DIFdel{machine, }\DIFdelend \DIFaddbegin \DIFadd{machines }\DIFaddend and random forests \DIFaddbegin \DIFadd{have also been used }\DIFaddend \cite{guilford_migration_2009, wang_machine_2019}. We may refer the reader to \cite{joo_navigating_2020} for a more detailed review of these methods.

Recently, deep learning methods have been suggested to be a potentially useful tool for behavioural pattern segmentation \cite{valletta_applications_2017}. Deep learning refers to a neural network with multiple layers of processing units \cite{lecun_deep_2015}. By decomposing the data through these multiple layers, deep neural networks may learn complex features for representing the data with a high level of abstraction at multiple scales. The trajectory of an animal being the result of complex processes at multiple \DIFdelbegin \DIFdel{spatiotemporal }\DIFdelend \DIFaddbegin \DIFadd{spatio-temporal }\DIFaddend scales \cite{nathan_movement_2008}, deep learning might be able to extract relevant representations of trajectories for performing tasks such as classification, segmentation or simulation. Deep learning has become the state-of-the-art framework for a wide range of problems in text, speech, audio and image processing and applications in ecology have mainly addressed image analysis and computer vision case-studies \cite{weinstein_computer_2018, christin_applications_2019}. Fewer studies have explored deep learning for animal trajectory data. Recurrent neural networks \DIFdelbegin \DIFdel{(RNNs) }\DIFdelend have been used for movement prediction \cite{ardakani_encoding_2017,rew_animal_2019}, and for the identification of representative movement patterns \cite{peng_deep_2019}. Very recently, an attention network has also been proposed for comparative analysis of  animal trajectories
\cite{maekawa_deep_2020}. Related to our study, a fully-connected network (\DIFaddbegin \DIFadd{hereafter, }\DIFaddend FCN) has been used to predict seabirds' diving in European shags, common guillemots and razorbills  \cite{browning_predicting_2018}. With a very simple \DIFdelbegin \DIFdel{fully-connected network }\DIFdelend \DIFaddbegin \DIFadd{FCN }\DIFaddend with 4 layers comprising hundreds of hidden nodes, this study demonstrated the improved accuracy of this approach over commonly-used behavioural classification methods. These promising results support new investigations to further explore the potential of deep learning schemes for movement ecology studies.

As in \cite{browning_predicting_2018}, this work addresses the inference of seabird diving behaviour from GPS data using Deep Learning methods. \DIFdelbegin \DIFdel{From a database of about 250 }\DIFdelend \DIFaddbegin \DIFadd{Besides, their FCN architecture, we investigated Convolutional Neural Networks and U-Networks \mbox{%DIFAUXCMD
\cite{ronneberger_u-net_2015}}\hspace{0pt}%DIFAUXCMD
, which are state-of-the-art architectures for time series and image data processing and shall better account for the time structure of trajectory data. As case-studies, we considered two tropical seabird genus with distinct diving behaviour (Boobies vs Cormorants). The associated datasets comprised 297 }\DIFaddend foraging trajectories derived from GPS data deployed simultaneously with pressure sensors for the identification of dives\DIFdelbegin \DIFdel{, we trained different deep networks within a supervised setting. Two network architectures were compared (Fully Connected Network vs U-Network) , and different trajectory representations were used (Time-series vs Distance Matrix) . These approaches were applied to two tropical seabird species with distinct diving behaviour (Boobies vs Cormorants) and compared to usual methods for dive prediction (Hidden Markov Model and First-Time-Passage) . We also evaluated the potential impact on the estimation of dives distribution}\DIFdelend . \DIFaddbegin \DIFadd{Our specific objectives were therefore (a) to confirm the performance of deep networks over state-of-the-art tools for dives identification, (b) to demonstrate generalization properties of trained network to predict dives of seabirds from other colonies and (c) to evaluate the benefits of a transfer learning strategy known as 'fine-tuning' for accross-species generalization.
}\DIFaddend


\section{Materials and Methods}
\subsection{Dataset}

GPS and TDR devices were \DIFdelbegin \DIFdel{fitted to Peruvian boobies (}\DIFdelend \DIFaddbegin \DIFadd{jointly fitted to breeding tropical seabirds both in Peru (92 Peruvian boobies, 106 Guanay cormorants) and Brazil (37 masked boobies). Peruvian boobies (}\DIFaddend \textit{Sula Variegata}) and Guanay \DIFdelbegin \DIFdel{Cormorant
}\DIFdelend \DIFaddbegin \DIFadd{cormorants }\DIFaddend (\textit{Leucocarbo Bougainvilli}) \DIFdelbegin \DIFdel{breeding off the coast of Peru }\DIFdelend \DIFaddbegin \DIFadd{were captured }\DIFaddend at Isla Pescadores (\DIFdelbegin \DIFdel{11.775}%DIFDELCMD < \degree %%%
\DIFdel{S, 77.265}%DIFDELCMD < \degree %%%
\DIFdelend \DIFaddbegin \DIFadd{11}\degree46\DIFadd{'30.34"S, 77}\degree15\DIFadd{'51.22"}\DIFaddend W) every year in December from 2008 to \DIFdelbegin \DIFdel{2013. Similar devices were also deployed on Peruvian boobies from }\DIFdelend \DIFaddbegin \DIFadd{2013 and at }\DIFaddend Isla Guanuape (\DIFdelbegin \DIFdel{8.566}%DIFDELCMD < \degree %%%
\DIFdel{S, 78.966}%DIFDELCMD < \degree %%%
\DIFdelend \DIFaddbegin \DIFadd{8}\degree32\DIFadd{'18.92"S, 78}\degree57\DIFadd{'42.72"}\DIFaddend W) in December \DIFdelbegin \DIFdel{2007.
}\DIFdelend \DIFaddbegin \DIFadd{2007, while masked boobies (}\textit{\DIFadd{Sula dactylatra}}\DIFadd{) were captured at Fernando de Noronha archipelago (3}\degree49\DIFadd{'9.71"S, 32}\degree23\DIFadd{'36.11"W) every year in April from 2017 to 2019. The GPS were attached with Tesa tape on the tail feathers for boobies and on the back feathers for cormorants for 1 to 2 days and the TDR were fixed on the bird's leg with a metal band. }\DIFaddend In total, GPS devices (Gipsy GPS, 25–30 g, Technosmart, Rome, Italy; i-gotU GPS GT 600, 25–30 g, Mobile action \DIFdelbegin \DIFdel{Tecnology}\DIFdelend \DIFaddbegin \DIFadd{Technology}\DIFaddend , NewTaipei City, Taiwan; MiniGPSlog 30 g, Earth and Ocean GPS, Kiel, Germany\DIFaddbegin \DIFadd{; Axy-trek 14g, Technosmart, Rome, Italy}\DIFaddend ) and time-depth recorders (TDRs, 3 g; resolution, 4 cm; G5 CEFAS Technology, Lowesoft, UK) were fitted to \DIFdelbegin \DIFdel{80 Peruvian boobies and 68 Guanay cormorants.
The GPS recorded locations at 1-s intervals and were attached with Tesa tape on the tail feathers for boobies and on the back feathers for cormorants for 1 to }\DIFdelend \DIFaddbegin \DIFadd{235 seabirds.
}

\DIFadd{After recovery, each GPS track was split into foraging trips by selecting locations further than a given distance to the colony and longer than a given time. Foraging trips were linearly interpolated to the TDR sampling resolution (i.e. 1s) and the coverage ratio was computed as in \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}}\hspace{0pt}%DIFAUXCMD
. It is defined as the ratio between the number of recorded fixes and the number of fixes that should have been recorded with a perfectly regular sampling in a fixed temporal window. Amount of missing data is detailed in Table \ref{table_data}. True dives were defined by depth measured by TDR higher than }\DIFaddend 2 \DIFdelbegin \DIFdel{days. The TDR recorded depth at 1-s intervals and were fixed on the bird's leg with a metal band. Each GPS track was then splitted into foraging trips}\DIFdelend \DIFaddbegin \DIFadd{meters. Each GPS position was thus associated with a boolean value detailing the 'dive' status}\DIFaddend . This dataset consists therefore in a total of \DIFdelbegin \DIFdel{234 }\DIFdelend \DIFaddbegin \DIFadd{297 }\DIFaddend foraging trips of seabirds with doubled-deployment GPS and TDR (see Table \DIFdelbegin \DIFdel{\ref{table1}}\DIFdelend \DIFaddbegin \DIFadd{\ref{table_data}}\DIFaddend ).

\begin{table}[!h]
 \caption{\textbf{Dataset Overview} - General statistics on the four linearly-interpolated datasets used in this study. (m $\pm$ s) is for respectively mean and standard deviation. Dives refer to the proportion of positions labeled as 'dive' (TDR-derived depth higher than 2 meters). Gaps consist in the proportion of missing fixes that have been linearly interpolated. Resting has been defined as the proportion of time with speeds inferior to 1 m.s-1 associated to non-diving behaviour.}
  \centering
  \hspace*{-1.5cm}
  \begin{tabular}{llllllll}
    \toprule
    Species  &  Colony Location & Nb of trips  & Trip Duration & Dives  & Dives Duration & Gaps & Resting \\
      &    &     & (min) & (\%) & (s) & (\%) & (\%) \\
    \midrule
    \textit{Sula variegata}         & Pescadores Island, Peru & 132 & 64 $\pm$ 37  & 1.3 \%  & 2.5 $\pm$ 1.3  & 2.2 \% & 4.4 \%\\
    \textit{Leucocarbo bougainvilli}& Pescadores Island, Peru & 79   & 143 $\pm$ 69  & 9.4 \%  & 12.9 $\pm$ 14.1 & 25.5 \% & 36.6 \%\\
    \textit{Sula variegata}         & Gua\~nape Island, Peru & 22   & 162 $\pm$ 75  & 0.7 \%  & 3.3 $\pm$ 2.5 & 1.5 \% & 6.6 \%\\
    \textit{Sula dactylatra}& Fernando de Noronha, Brazil & 64 & 491 $\pm$ 377  & 0.2 \%  & 2.2 $\pm$ 1.4 & 6.1 \% & 33 \%\\
    \bottomrule
  \end{tabular}
  \label{table_data}
\end{table}

\DIFdelbegin \DIFdel{Missing fixes in GPS data were linearly interpolated.
The coverage ratio was computed as in \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}}\hspace{0pt}%DIFAUXCMD
.
It is defined as the ratio between the number of recorded fixes and the number of fixes that should have been recorded with a perfectly regular sampling in a fixed temporal window.
True dives were defined by depth measured by TDR larger than 2 meters. To assess the impact of the sampling rate of the trajectory data, we resampled each trip every 5, 15 s and 30s. Temporal windows containing at least one dive were classified as dives.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdel{The two datasets from Pescadores Island, corresponding to the two study species,  were splitted into training, validation and test datasets with respective size of 70\%  , 20\% and 10\%. The dataset from Guañape was only used as test dataset in order to evaluate the the generalization performance of trained networks, }%DIFDELCMD < {\em %%%
\DIFdel{i.e.}%DIFDELCMD < } %%%
\DIFdel{their ability to deal with datasets that have not been used during the training process.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdelend \subsection{Deep Neural Network Architectures}

In this work, we investigated deep neural networks. As baseline architecture, we considered \DIFaddbegin \DIFadd{the }\DIFaddend fully-connected network \DIFaddbegin \DIFadd{(FCNet) }\DIFaddend proposed in \cite{browning_predicting_2018}. Besides, as \DIFdelbegin \DIFdel{the considered problem may be stated as a segmentation issue, an adaption of a U-Net architecture naturally arised as a state-of-the-art solution}\DIFdelend \DIFaddbegin \DIFadd{described in Figure \ref{figure_network} we considered a fully convolutional neural network (CNNet) and a U-shape network particularly adapted to segmentation problems (UNet) \mbox{%DIFAUXCMD
\cite{ronneberger_u-net_2015}}\hspace{0pt}%DIFAUXCMD
}\DIFaddend . We describe below these \DIFdelbegin \DIFdel{two }\DIFdelend \DIFaddbegin \DIFadd{three }\DIFaddend architectures and the associated supervised training procedure. We refer the reader to \cite{christin_applications_2019} for an introduction to deep neural networks dedicated to ecologists.

\DIFaddbegin \begin{figure}[!h]
  \includegraphics[scale=0.45]{figure_network.png}
  \caption{\textbf{\DIFaddFL{Network Architectures}} \DIFaddFL{- CNNet refers to a fully convolutional neural network. UNet refers to a U-shape network. A channel refer to deep learning terminology and describes a representation of the input data as output of some computation layer. Conv1d, MaxPool, and UpConv1d are abbreviations for usual deep learning operations. Details can be found on pytorch's documentation \mbox{%DIFAUXCMD
\cite{paskze_pytorch_2019} }\hspace{0pt}%DIFAUXCMD
}}
  \label{figure_network}
\end{figure}

\DIFaddend \subsubsection{Fully-Connected Network (\DIFdelbegin \DIFdel{FCN}\DIFdelend \DIFaddbegin \DIFadd{FCNet}\DIFaddend )}
The first architecture implemented was similar to the fully-connected network presented by \cite{browning_predicting_2018}. As input vector, we used the concatenation of \DIFdelbegin \DIFdel{longitude, latitude }\DIFdelend \DIFaddbegin \DIFadd{step speed, turning angle }\DIFaddend and coverage time series for over a 20-second window. This input vector is fed to a layer of 100 nodes followed by 3 layers of 500 nodes. Each node applies a linear transformation to the incoming data and a non-linear activation chosen as a Rectified Linear Unit (ReLU - $\textsc{ReLU}(x) = \max(0,x)$). The last layer applied a softmax binary function so that the output of the vector is a time series of values between  0 and 1, which can be interpreted as binary classification probabilities. This  architecture is a classical example of a so-called multilayer perceptron, with a rectified linear activation which is the default activation in deep learning architectures. Overall, this architecture involves \DIFdelbegin \DIFdel{$5.10^{5}$ }\DIFdelend \DIFaddbegin \DIFadd{500k }\DIFaddend parameters.

\DIFaddbegin \newpage

\DIFaddend \subsubsection{\DIFdelbegin \DIFdel{U-Network with Distance Matrix Encoder }\DIFdelend \DIFaddbegin \DIFadd{Fully Convolutional Networks }\DIFaddend (\DIFdelbegin \DIFdel{DME-UNet}\DIFdelend \DIFaddbegin \DIFadd{CNN}\DIFaddend )}
\DIFdelbegin \DIFdel{As described in Figure \ref{figure3}, we also introduced a novel architecture based on a U-Network (UNet)  \mbox{%DIFAUXCMD
\cite{ronneberger_u-net_2015}}\hspace{0pt}%DIFAUXCMD
. This architecture exploits a
Distance Matrix Encoder (DME) to represent geometrical features along a trajectory.
Similarly to the FCNetarchitecture}\DIFdelend \DIFaddbegin \DIFadd{Convolutional networks exploit convolutional layers and are the state-of-art architectures for a wide range of applications, especially for signal and image processing tasks \mbox{%DIFAUXCMD
\cite{alom_state---art_2019}}\hspace{0pt}%DIFAUXCMD
. Thus, we investigated a basic neural network fully composed of convolutional layers. Similar to FCNet}\DIFaddend , its input vector is the concatenation of \DIFdelbegin \DIFdel{longitude, latitude }\DIFdelend \DIFaddbegin \DIFadd{step speed, turning angle }\DIFaddend and coverage time series over a 20-second window \DIFdelbegin \DIFdel{and it outputs }\DIFdelend \DIFaddbegin \DIFadd{but its output is }\DIFaddend a vector of diving probability of the same length. \DIFaddbegin \DIFadd{Overall, this architecture U-Net involves 5k parameters.
}\DIFaddend

\DIFdelbegin %DIFDELCMD < \begin{figure}[!h]
%DIFDELCMD <   %%%
\DIFdelFL{\hspace*{-2cm}
  }%DIFDELCMD < \includegraphics[scale=0.45]{figure3.png}
%DIFDELCMD <   %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\textbf{\DIFdelFL{DME-UNet Architecture}} %DIFAUXCMD
\DIFdelFL{- This network is composed of two blocks entitled Distance Matrix Encoder (DME) and U-Network (UNet). It takes as input a GPS of 20 successive positions and outputs a diving probability to each of these positions. A channel refer to deep learning terminology and describes a representation of the input data as output of some computation layer. Conv1d, Conv2dn MaxPool, and UpConv1d are abbreviations for usual deep learning operations in convolutional networks. Details can be found on pytorch's documentation \mbox{%DIFAUXCMD
\cite{paskze_pytorch_2019} }\hspace{0pt}%DIFAUXCMD
}}
  %DIFAUXCMD
%DIFDELCMD < \label{figure3}
%DIFDELCMD < \end{figure}
%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdel{The DME takes as input a distance matrix.
This distance matrix is simply obtained by computing the orthodromic distance between each pair of positions in the input track. Its lines and rows are ordered in increasing time.
The idea behind this representation of trajectory data is that longitude and latitude time-series may not be the best representations for neural-network-based methods since movement trajectories inherently contain 2D spatial information which might not be easily perceivable in simple time-series.
The performance of machine learning methods is heavily dependent on the choice of data representation (or features) on which they are applied \mbox{%DIFAUXCMD
\cite{bengio_representation_2014}}\hspace{0pt}%DIFAUXCMD
. We expect the distance matrix representation to better encode 2D spatial patterns along a trajectory.
Given a matrix distance, the DME applies a 2-dimensional convolutionnal layer with 8 channels (i.e. 8 output features) combined with rectifier linear unit activations.
As a feature extraction step, we then sum the resulting output over the horizontal direction to extract a 8-dimensional feature vector at each position of the considered trajectory segment.
In short, this network can be regarded as a trainable function that would compute residence time defined as in \mbox{%DIFAUXCMD
\cite{barraquand_animal_2008}}\hspace{0pt}%DIFAUXCMD
, but with circle of different radius which values will be adjusted automatically by the network.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdel{We adapt }\DIFdelend \DIFaddbegin \subsubsection{\DIFadd{U-Network (UNet)}}
\DIFadd{As the considered problem can be seen as a segmentation task, }\DIFaddend a U-Net architecture \DIFdelbegin \DIFdel{, which is the }\DIFdelend \DIFaddbegin \DIFadd{naturally arises as a }\DIFaddend state-of-the-art \DIFdelbegin \DIFdel{neural architecture for segmentation tasks \mbox{%DIFAUXCMD
\cite{ronneberger_u-net_2015}}\hspace{0pt}%DIFAUXCMD
, to a multivariate 1-dimensional setting. As inputs, we provide the U-Net with a 11-dimensional time series which concatenate the raw longitude, latitude and coverage ratio time series and the output of the DME. }\DIFdelend \DIFaddbegin \DIFadd{solution \mbox{%DIFAUXCMD
\cite{ronneberger_u-net_2015}}\hspace{0pt}%DIFAUXCMD
. }\DIFaddend The key feature of \DIFdelbegin \DIFdel{the U-Net }\DIFdelend \DIFaddbegin \DIFadd{this }\DIFaddend architecture is to combine the information extracted by convolutional blocks applied at \DIFaddbegin \DIFadd{different }\DIFaddend temporal scales. To achieve this multi-scale analysis, the U-Net applies pooling layer to coarsen the time resolution and interpolation layers (UpConv1d layers) to increase the time resolution as sketched in Fig.\DIFdelbegin \DIFdel{\ref{figure3}}\DIFdelend \DIFaddbegin \DIFadd{\ref{figure_network}}\DIFaddend . At each scale, we apply a specific convolution block. We concatenate its output with the interpolated output of the coarser scale to a convolutional block, whose output is interpolated to the finer resolution. Overall, we may notice that the output of the U-Net architecture is a time series with the same time resolution as the input time series. Similarly to \DIFdelbegin \DIFdel{the fully-connected architecture}\DIFdelend \DIFaddbegin \DIFadd{FCNet and CNNet}\DIFaddend , the last layer applies a \DIFdelbegin \DIFdel{sigmoïd }\DIFdelend \DIFaddbegin \DIFadd{sigmoid }\DIFaddend activation to transform the output into a time series of diving probabilities. Overall, this architecture \DIFdelbegin \DIFdel{(DME + }\DIFdelend U-Net \DIFdelbegin \DIFdel{) involves $2.10^{4}$ parameterswhich is approximately 30 times less than for the FCNet}\DIFdelend \DIFaddbegin \DIFadd{involves 20k parameters}\DIFaddend .

\subsubsection{Network Training and Validation}
Given a selected neural network architecture, the training procedure relies on a supervised learning scheme using a weighted binary cross entropy as loss function. This function evaluates the performance of a prediction by comparing the dive prediction (output of the model) with the true dives defined by TDR data. We consider a weighted version of the binary cross entropy because of the unbalanced presence of dive and no-dive behaviour in the studied trajectories (see Table \DIFdelbegin \DIFdel{\ref{table1}}\DIFdelend \DIFaddbegin \DIFadd{\ref{table_data}}\DIFaddend ). The objective is to penalize more for mistakes on the smaller class (diving behaviour) than for false positive, thus ensuring for convergence. In the reported experiments, the weight was empirically set to 5 for cormorants datasets and 30 for boobies dataset.

The minimisation of the training loss exploits the Adam stochastic optimizer \cite{kingma_adam_2014}. Networks were evaluated on training and validation datasets every epoch (defined as one pass through the entire train dataset). We consider an early-stopping criterion such that the training procedure was stopped as soon as the validation loss started increasing. Overall, given a trajectory the diving probability at a given location was assessed by computing the mean probability of all predictions derived from all 20 positions windows. These models were implemented, trained and tested with python using pytorch library \cite{paskze_pytorch_2019}. Our pytorch Code is available on our github repository: https://github.com/AmedeeRoy/BirdDL.

\subsection{Benchmarked methods}
Two classical methods for dive prediction First-Passage Time (FPT), and Hidden Markov Models (HMM) were evaluated for intercomparison purposes. FPT was computed following \cite{fauchald_using_2003}, by selecting the radius that maximizes the variance of passage times. Time passage values were converted into a probability of dives with min-max normalization. Regarding HMMs, we applied the momentuHMM R package \cite{mcclintock_momentuhmm_2018}. We implemented HMMs with 3 \DIFdelbegin \DIFdel{behavioural modes }\DIFdelend \DIFaddbegin \DIFadd{(resp. 4) behavioural modes for boobies (resp. cormorants) }\DIFaddend associated to traveling, searching\DIFdelbegin \DIFdel{and diving }\DIFdelend \DIFaddbegin \DIFadd{, diving and resting }\DIFaddend behaviours. This approach represents trajectories as a sequence of steps and angles. It models steps as random variables following a gamma marginal distribution and angle following a von mises marginal distribution. \DIFdelbegin \DIFdel{In this HMM setting, the coverage data was used as covariate in the transition probability matrix, assuming that low coverage ratio might provide a proxy of the likelihood of the diving behaviour and vice-versa. }\DIFdelend We may point out that the HMMs direclty provide as outputs a likelihood value of the diving behaviour.

\subsection{Evaluation scheme}
We describe below the evaluation scheme we implemented to assess the performance of the proposed neural network approaches. We first \DIFdelbegin \DIFdel{focuses }\DIFdelend \DIFaddbegin \DIFadd{focus }\DIFaddend on the benchmarking of the performance of the considered approaches in terms of dive prediction accuracy \DIFaddbegin \DIFadd{for different data input}\DIFaddend . For the proposed neural network architectures, we further analyze \DIFdelbegin \DIFdel{the impact on the }\DIFdelend \DIFaddbegin \DIFadd{their generalization properties. The methodological framework is exposed in Figure \ref{figure_framework}.
}

\begin{figure}[!h]
  \includegraphics[scale=0.7]{figure_framework.png}
  \caption{\textbf{\DIFaddFL{Evaluation scheme}} \DIFaddFL{- (1) The datasets from Pescadores Island (see Tab. \ref{table_data}) have been used to train, validate and test deep networks. UNet, CNN and FCNet refer to the deep network architectures used in this study (see Fig. \ref{figure_network}). (2) The trained networks have been directly used to predict dives on two other datasets without any additional training (Datasets from Guañape Island and Fernando de Noronha). (3) The dataset from Brazil have been used to train, validate and test deep networks. However, the deep networks previously obtained at step (1) have been used for weight initialization. This is known as Fine-tuning.}}
  \label{figure_framework}
\end{figure}

\paragraph{\DIFadd{(a) Network training}}
\DIFadd{We assessed the }\DIFaddend dive prediction performance of \DIFdelbegin \DIFdel{different data types used as inputs as well as their generalization performance }\DIFdelend \DIFaddbegin \DIFadd{the 5 benchmarked methods (FPT, HMM, FCNet, CNNet and UNet) considering trajectory data derived from the two dataset from Pescadores Island (see Tab. \ref{table_data}). To test for the effect of temporal resolution, the two datasets have been downsampled every 5, 15 and 30s. When downsampling, temporal windows containing at least one dive were classified as dives. Each dataset were then splitted into training, validation and test datasets with respective size of 50\%, 30\% and 20\%. Deep networks were trained and selected based on the training and validation datasets. All approaches were finally compared on the testing dataset. Overall, this led to the quantitative comparison of the performance of 5 models on 6 datasets all listed in Table \ref{table_training}}\DIFaddend .

\DIFdelbegin \paragraph{\DIFdel{Dive prediction performance}}
%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdelend As evaluation metrics for dive prediction, we evaluated the receiver operating characteristics curve (ROC) \DIFdelbegin \DIFdel{, the area under the curve (AUC) as well as the binary cross entropy (BCE) for the test datasets. For binary classification, the ROC curve plots the }\DIFdelend \DIFaddbegin \DIFadd{which  describes the performance of a binary classifier. It consists in plotting the }\DIFaddend true positive rate (i.e. true predicted dives) against the false positive rate (i.e. false predicted dives). We obtain this curve by varying the probability threshold defining dive/no dive behaviours. \DIFaddbegin \DIFadd{Moreover, we evaluate the area under the curve (AUC) as well as the binary cross entropy (BCE) for the test datasets. }\DIFaddend Regarding the AUC, it was estimated by integrating the ROC curve along the x axis using the composite trapezoidal rule. For neural network approaches, we also analyzed the value of \DIFaddbegin \DIFadd{the }\DIFaddend training loss for the training and test datasets.

\paragraph{\DIFdelbegin \DIFdel{Data inputs}\DIFdelend \DIFaddbegin \DIFadd{(b) Generalization performance of pre-trained networks}\DIFaddend }
\DIFdelbegin \DIFdel{Both studied species breed in the most productive upwelling system, the Humboldt Current System (HCS) and feed on the same preys, i. e. Peruvian anchovies \mbox{%DIFAUXCMD
\cite{jahncke_diets_1998}}\hspace{0pt}%DIFAUXCMD
. However, they are known to have distinct foraging strategies: boobies are plunge divers reaching in average about 2 m depth and spending most of the time in fly, while cormorants dive deeper and longer in average, reach up to }\DIFdelend \DIFaddbegin \DIFadd{In this section, we evaluated the generalization performance through the application of models trained on Pescadores dataset to data that have not been used during the training process. In particular, we evaluate previously fitted deep networks performance on the two datasets from Guañape Island and from Fernando de Noronha Archipelago, composed of Peruvian boobies and masked boobies trajectories, respectively. In this experiment, we compared the dive prediction performance of FPT and HMM methods to the best FCNet, CNN and UNet models. Beyond AUC and BCE performance metrics, we also evaluated the relevance of the estimated maps of dive distributions. The later were computed using a weighted Kernel Density Estimator (KDE) using dive probabilities as weighing factor. As groundtruth, we considered the map of dive distributions estimated from true dive locations defined by TDR data. Kernel densities were estimated using a 0.01$\times$0.01}\degree \DIFadd{grid and a bandwith of 0.25}\degree\DIFadd{. From these maps, we evaluated an means square error (MSE) as an integrated performance metrics for the different approaches \mbox{%DIFAUXCMD
\cite{wilson_distancebased_2011}}\hspace{0pt}%DIFAUXCMD
.
}

\paragraph{\DIFadd{(c) Network Fine-Tuning}}
\DIFadd{Transfer learning refers to the fact of using knowledge that was gained from solving one problem and applying it to a new but related problem. For this purpose, a solution known as 'fine-tuning' consists in using a trained model as the initialization of the training scheme rather than training a new model from scratch. Thus, we evaluated the benefits of fine-tuning for predicting dives of the 15s-resampled Brazilian dataset (Tab. \ref{table_data}) based on the deep networks fitted on the dataset from Pescadores. The Brazilian dataset was therefore split into training, validation and test datasets with respective size of 50\%, }\DIFaddend 30\DIFdelbegin \DIFdel{m depth, and spend up to 40\% of the time in water \mbox{%DIFAUXCMD
\cite{weimerskirch_foraging_2012}}\hspace{0pt}%DIFAUXCMD
. We assessed the dive prediction performance of the benchmarked methods when considering trajectory data derived from these two distinct seabird and associated with different time resolutions, more precisely trajectory data sampled at }\DIFdelend \DIFaddbegin \DIFadd{\% and 20\%. We then trained models from scratch and using fine-tuning for the three studied network architectures and following the learning procedure presented before. We also evaluate the impact of the training dataset size by randomly selecting respectively 1, }\DIFaddend 5, 15 and \DIFdelbegin \DIFdel{30s. We specifically evaluated the relative importance of coverage data and of the Distance Matrix Encoder by training neural network approaches with and without this information. As mentioned above, we also applied the HMM with and without coverage data used as covariate in the transition probability matrix. Overall, this led to the quantitative comparison of the performance of 17 models and 6 datasets all listed in Table \ref{table2}}\DIFdelend \DIFaddbegin \DIFadd{30 foraging trips for the training step. All models were finally compared to HMM and FPT methods on the testing dataset and using the AUC evaluation metric}\DIFaddend .

\begin{table}[h]
 \caption{\textbf{Deep Networks Training} - Performance metrics for all trained deep networks on the trajectories of Pescadores along with benchmarked methods used for comparison. AUC means the Area Under the ROC curve, BCE is for binary cross entropy computed on the testing trajectories. Train and Validation Loss correspond to the loss computed after model training on respectively training and validation datasets. SV is for Peruvian boobies (\textit{Sula variegata)}, LB is for Guanay cormorants (\textit{Leucocarbo bougainvilli})}
  \centering
  \begin{tabular}{llllllllll}
    \toprule
    Dataset  &  Resolution &  Model &  AUC & BCE & F-score & Train Loss & Validation Loss & Reference Name\\
    \midrule
    SV       & 5s  & FPT    & 0.62 & 0.70 & 0.55 & - & -  & -\\
(Pescadores) &     & HMM    & 0.86 & 1.07 & 0.69 & - & -  & - \\
             &     & FCNet  & 0.89 & 0.38 & 0.81 & 0.61 & 0.61 & SV\_FCNet\_5s \\
             &     & CNNet  & 0.94 & 0.29 & 0.88 & 0.48 & 0.49 & SV\_CNNet\_5s \\
             &     & {\bf UNet} & {\bf 0.96} & {\bf 0.23} & {\bf 0.91} & {\bf 0.48} & {\bf 0.45} & {\bf SV\_UNet\_5s}\\
             & 15s & FPT    & 0.71 & 0.79 & 0.66 & - & - & - \\
             &     & HMM    & 0.87 & 2.39 & 0.84 & - & - & - \\
             &     & FCNet  & 0.82 & 0.81 & 0.80 & 1.35 & 1.16 & SV\_FCNet\_15s \\
             &     & CNNet  & 0.91 & 0.58 & 0.85 & 0.89 & 0.86 & SV\_CNNet\_15s \\
             &     & {\bf UNet} & {\bf 0.93} & {\bf 0.57} & {\bf 0.86} & {\bf 0.87} & {\bf 0.79} & {\bf SV\_UNet\_15s} \\
             & 30s & FPT    & 0.73 & 0.97 & 0.70 &  - & - & - \\
             &     & HMM    & 0.84 & 1.22 & 0.68 & - & - & - \\
             &     & FCNet  & 0.82 & 1.10 & 0.79 & 1.69 & 1.74 & SV\_FCNet\_30s \\
             &     & CNNet  & 0.85 & 0.98 & 0.80 & 1.55 & 1.47 & SV\_CNNet\_30s \\
             &     & {\bf UNet} & {\bf 0.91} & {\bf 0.73} & {\bf 0.86} & {\bf 1.12} & {\bf 1.10} & {\bf SV\_UNet\_30s} \\
    \midrule
    LB        & 5s  & FPT    & 0.61 & 1.59 & 0.57 & - & - & - \\
(Pescadores) &     & HMM    & 0.78 & 1.42 & 0.72 & - & - & - \\
             &     & FCNet  & 0.87 & 0.40 & 0.79 & 0.55 & 0.67 & LB\_FCNet\_5s \\
             &     & CNNet  & 0.92 & 0.30 & 0.84 & 0.48 & 0.57 & LB\_CNNet\_5s \\
             &     & {\bf UNet} & {\bf 0.93} & {\bf 0.28} & {\bf 0.85} & {\bf 0.46} & {\bf 0.54} & {\bf LB\_UNet\_5s} \\
             & 15s & FPT    & 0.58 & 1.73 & 0.62 & - & - & - \\
             &     & HMM    & 0.76 & 3.35 & 0.72 & - & - & - \\
             &     & FCNet  & 0.67 & 0.77 & 0.75 & 0.85 & 0.94 & LB\_FCNet\_15s \\
             &     & CNNet  & 0.89 & 0.43 & 0.85 & 0.60 & 0.73 & LB\_CNNet\_15s \\
             &     & {\bf UNet} & {\bf 0.90} & {\bf 0.37} & {\bf 0.83} & {\bf 0.52}& {\bf 0.76} & {\bf LB\_UNet\_15s} \\
             & 30s & FPT    & 0.56 & 1.81 & 0.62 & - & - & - \\
             &     & HMM    & 0.75 & 2.90 & 0.74 & - & - & - \\
             &     & FCNet  & 0.65 & 0.92 & 0.75 & 0.96 & 1.10 & LB\_FCNet\_30s \\
             &     & CNNet  & 0.74 & 0.74 & 0.76 & 0.86 & 1.01 & LB\_CNNet\_30s\\
             &     & {\bf UNet} & {\bf 0.88} & {\bf 0.37} & {\bf 0.83} & {\bf 0.97} & {\bf 1.05} & {\bf LB\_UNet\_30s} \\
    \bottomrule
  \end{tabular}
  \label{table_training}
\end{table}

\DIFdelbegin \paragraph{\DIFdel{Generalization properties}}
%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdel{When considering neural network approaches, training models which may apply beyond the considered training framework is a key feature, generally referred to as the generalization performance of the trained neural networks. Here, we evaluated this generalization performance through the application of models trained on Pescadores dataset to the Gua\~nape dataset.
This dataset is composed of Peruvian boobies trajectories but from a different breeding colony. Beyond the different in the case-study region, we expect peruvian boobies behaviour to share common features across colonies, so that models fitted to the trajetory data of a given colony might still be meaningful when applied to another colony.
In this experiment, we compared the dive prediction performance of FPT and HMM methods to the best FCNet and DME-UNet models. Beyond AUC and BCE performance metrics, we also evaluated the relevance of the estimated map of dive distributions. The later were computed using a weighted Kernel Density Estimator (KDE) using dive probabilities as weighing factor. As groundtruth, we considered the map of dive distributions estimated from true dive locations defined by TDR data. From these maps, we evaluated an Hellinger distance as an integrated performance metrics for the different approaches \mbox{%DIFAUXCMD
\cite{wilson_distancebased_2011}}\hspace{0pt}%DIFAUXCMD
.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdelend \section{Results}

We \DIFdelbegin \DIFdel{detailed }\DIFdelend \DIFaddbegin \DIFadd{detail }\DIFaddend below the numerical experiments performed in this study to assess the relevance of the proposed neural network approaches to predict dive behaviour of \DIFdelbegin \DIFdel{Peruvian }\DIFdelend boobies and cormorants from trajectory data.

\paragraph{\DIFdelbegin \DIFdel{Overall performance}\DIFdelend \DIFaddbegin \DIFadd{(a) Network Training}\DIFaddend }
\DIFdelbegin \DIFdel{For all datasets, }\DIFdelend \DIFaddbegin \DIFadd{On the Pescadores Island dataset used for network training, we reported a contrasted performance of }\DIFaddend the different methods\DIFdelbegin \DIFdel{obtained contrasted performance results}\DIFdelend , with AUC going from \DIFdelbegin \DIFdel{0.71 to 0.97 }\DIFdelend \DIFaddbegin \DIFadd{0.61 to 0.96 }\DIFaddend (see Table \DIFdelbegin \DIFdel{\ref{table2}}\DIFdelend \DIFaddbegin \DIFadd{\ref{table_training}}\DIFaddend ), which corresponds in the best cases to correct prediction rates of diving and non-diving behaviour of approximately \DIFdelbegin \DIFdel{90}\DIFdelend \DIFaddbegin \DIFadd{95}\DIFaddend \% and of \DIFdelbegin \DIFdel{70}\DIFdelend \DIFaddbegin \DIFadd{60}\DIFaddend \% in the worst cases (see Figure \DIFdelbegin \DIFdel{\ref{figure1}}\DIFdelend \DIFaddbegin \DIFadd{\ref{figure_roc_training}}\DIFaddend ). Overall, \DIFdelbegin \DIFdel{neural networks-based approaches obtained better performance than the state-of-the art methods, with highest AUC (around 0.9) and lowest binary cross entropy (around 0.5). First-Passage Time obtained quasi systematically the lowest AUC, and the Hidden Markov Models had most of the time AUC around }\DIFdelend \DIFaddbegin \DIFadd{all methods performed better at predicting the dives of boobies than those of cormorants. The UNet obtained systematically the best prediction performance with averaged AUC of 0.93 (resp. 0.90) for boobies and cormorants respectively. The CNN also achieved very good predictions, consistently performing at least as well as state-of-the-art tools with averaged AUC of 0.9 (resp. }\DIFaddend 0.85\DIFdelbegin \DIFdel{but the highest BCE. State-of-the-art methods were outperformed by neural networks specifically for the 5s resolution datasets, with AUC improvements up to 15\% with neural networks over HMM. In particular, the DME-UNet was the most consistent method, being able to get better performance on most datasets, and to improve substantially the performance of the FCNet proposed by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}}\hspace{0pt}%DIFAUXCMD
. As illustration, on }\DIFdelend \DIFaddbegin \DIFadd{). The lowest performance was reported for the FPT approach, which never predicted dives with AUC higher than 0.73. The HMM obtained relatively good performance on }\DIFaddend the \DIFdelbegin \DIFdel{boobies dataset, BCEwas approximately two times lower with the DME-UNet than with the FCNet, and the DME-UNet obtained systematically higher AUC .
}\DIFdelend \DIFaddbegin \DIFadd{boobies dataset with AUC indices around 0.85, yet it did not get AUC higher than 0.76 on the cormorants dataset. It also obtained the highest BCE, approximately 2 to 10 times higher than the UNet. Regarding the FCNet, the AUC index ranged from
0.65 to 0.89, showing a much greater variability than for CNN and UNet architectures. The best neural network predictions for Pescadores dataset are illustrated in Fig. \ref{figure_map_prediction}.
}\DIFaddend

\DIFdelbegin %DIFDELCMD < \begin{figure}[!h]
%DIFDELCMD <   \centering
%DIFDELCMD <   \includegraphics[scale=0.5]{figure1.png}
%DIFDELCMD <   %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\textbf{\DIFdelFL{Comparison of algorithms}} %DIFAUXCMD
\DIFdelFL{- ROC curves obtained from the prediction of 4 algorithms, First-Time Passage (FPT), 3-states Hidden Markov Models (HMM), Fully-Connected Network (FCN) and U-Network with a Distance Matrix Encoder (DME-UNet) on 4 distinct test datasets derived from two seabirds species breeding in Pescadores Island from 2008 to 2013}}
  %DIFAUXCMD
%DIFDELCMD < \label{figure1}
%DIFDELCMD < \end{figure}
%DIFDELCMD <

%DIFDELCMD < %%%
\paragraph{\DIFdel{Impact of the temporal resolution}}
%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdel{Interestingly, on the cormorant dataset the sampling resolution}\DIFdelend \DIFaddbegin \DIFadd{Interestingly, deep networks were relatively sensitive to the sampling resolution, whereas it }\DIFaddend did not affect much the performance of the \DIFdelbegin \DIFdel{neural network approaches (DME-UNet with AUC of 0.95) whereas state-of-the-art methods FPT /HMM had increasing AUC with larger resolution going from respectively 0.73/0.78 to 0.79/0.86 (see Table \ref{table2}). At the opposite, on the peruvian datasets the }\DIFdelend FPT \DIFdelbegin \DIFdel{/HMM methods had constant performance disregarding the sampling resolution (AUC around 0.76/0.88), while deep learning tools had decreasing AUC with larger resolution. In particular, the dataset of Peruvian boobies with the larger resolution (i. e. }\DIFdelend \DIFaddbegin \DIFadd{and HMM approaches. For both species, the higher the resolution, the better the performance for UNets, CNNs and FCNets. For instance, we reported a mean AUC of 0.92 for a 5s resolution vs. 0.81 for a }\DIFaddend 30s \DIFdelbegin \DIFdel{) is the only one where neural networks did not do any better than }\DIFdelend \DIFaddbegin \DIFadd{resolution. This was particularly true for the CNN and mostly for the FCNet which did not performed better than HMM on the 30s-resoluted datasets, whereas they were able to outperform }\DIFaddend state-of-the-art \DIFdelbegin \DIFdel{. Yet, if DME-UNet's performance are pretty much equivalent to the highest AUC obtained by HMM (AUC of 0.87) , on this dataset the FCNet had lowest prediction performance (AUC of 0.76)(see Figure \ref{figure1}). }\DIFdelend \DIFaddbegin \DIFadd{approaches on the 5s-resoluted datasets.
}\DIFaddend

\DIFdelbegin \paragraph{\DIFdel{Impact of data inputs}}
%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdel{Deep networks had substantial increase of accuracy through the coverage ratio data, all three networks FCNet, UNet and DME-UNet having very high prediction accuracy with AUC around 0.95 (see Table \ref{table2}) . Yet, without coverage information, accuracy was way poorer with AUC around 0.7, except for the network using a Distance Matrix Encoder (DME-UNet)that maintains an AUC at 0.92. At the opposite, the removal of coverage data did not change significantly the performance indexes of the HMM with a relatively constant AUC of 0.87 (see Figure \ref{figure2}). }%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdelend \begin{figure}[!h]
  \centering
  \DIFdelbeginFL %DIFDELCMD < \includegraphics[scale=0.5]{figure2.png}
%DIFDELCMD <   %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\textbf{\DIFdelFL{Comparison of data inputs}} %DIFAUXCMD
\DIFdelFL{- ROC curves obtained from the prediction of 3 deep networks, Fully-Connected Network (FCN) and U-Network with/without a Distance Matrix Encoder (resp. UNet / DME-UNet) on the test dataset derived from Peruvian boobies sampled at 5s breeding in Pescadores Island from 2008 to 2013}}
  %DIFAUXCMD
%DIFDELCMD < \label{figure2}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale=0.5]{figure_roc_training.png}
  \caption{\textbf{\DIFaddFL{Performance of Deep Networks on Pescadores Dataset}} \DIFaddFL{- ROC curves obtained from the prediction of 5 algorithms, First-Time Passage (FPT), Hidden Markov Models (HMM), Fully-Connected Network (FCNet), Fully-Convolutional Network (CNN) and U-Network (UNet) on 2 distinct test datasets resampled at 3 different resolutions (5, 15 and 30s) derived from two seabirds species breeding in Pescadores Island from 2008 to 2013. SV stands for Peruvian boobies (}\textit{\DIFaddFL{Sula variegata}}\DIFaddFL{), and LB stands for Guanay cormorants (}\textit{\DIFaddFL{Leucocarbo bougainvilli}}\DIFaddFL{).}}
  \label{figure_roc_training}
\DIFaddendFL \end{figure}

\DIFdelbegin \paragraph{\DIFdel{Maps of diving probabilities}}
%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdel{We further analysed the relevance of the dive predictions through the estimated dive distributions maps reported in Figure \ref{figure4a} and \ref{figure4b}. For both species, we can observe neural networks and HMM approaches have contrasted outputs (either very high or low diving probabilities), while the FPT approach is the one that discriminate the least dive from non-diving behaviours. Moreover, these maps also point out that from all methods false positive are predicted with high probabilities in areas where no true dives occurred (i.e. isolated blue circle with high radius). Yet, it is particularly visible from FCNet and HMM output and specifically in the vicinity of the colony.
}%DIFDELCMD <

%DIFDELCMD < \newpage
%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdelend \begin{figure}[!h]
  \centering
  \DIFdelbeginFL %DIFDELCMD < \includegraphics[scale=0.5]{figure4a.png}
%DIFDELCMD <   %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\textbf{\DIFdelFL{Maps of Peruvian boobies predicted dives}} %DIFAUXCMD
\DIFdelFL{- Maps of the trajectories. Red points represent true dive derived from TDR data. Blue points represents diving probabilities of each location with radius increasing for higher probabilities. These probabilities are the results of four methods on the same Dataset (SV 5s), with our proposed network DME-UNet (top left), the fully connected network used by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}  }\hspace{0pt}%DIFAUXCMD
FCNet (top right), the 3 states Hidden Markov Models HMM (bottom left), and the First Time Passage apporach FPT (bottom right)}}
  %DIFAUXCMD
%DIFDELCMD < \label{figure4a}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale=0.5]{figure_map_prediction.png}
  \caption{\textbf{\DIFaddFL{Maps of predicted dives for all 'test' datasets}} \DIFaddFL{- Red points represent true dive derived from TDR data. Blue points represent diving probabilities at each location with radius increasing for higher probabilities. These probabilities are the outputs of the best deep networks for each dataset: Peruvian boobies from Pescadores (top left), and from Guañape Island (bottom left), Guanay cormorants from Pescadores Island (top right), and masked boobies from Fernando de Noronha archipelago (bottom right). SV stands for Peruvian boobies (}\textit{\DIFaddFL{Sula variegata}}\DIFaddFL{), LB for Guanay cormorants (}\textit{\DIFaddFL{Leucocarbo bougainvilli}}\DIFaddFL{) and SD for masked boobies (}\textit{\DIFaddFL{Sula dactylatra}}\DIFaddFL{). Bathymetry is shown in grey.}}
  \label{figure_map_prediction}
\DIFaddendFL \end{figure}

\DIFdelbegin %DIFDELCMD < \begin{figure}[!h]
%DIFDELCMD <   \centering
%DIFDELCMD <   \includegraphics[scale=0.5]{figure4b.png}
%DIFDELCMD <   %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\textbf{\DIFdelFL{Maps of Guanay cormorants predicted dives}} %DIFAUXCMD
\DIFdelFL{- Maps of the testing trajectories. Red points represent true dive derived from TDR data. Blue points represents diving probabilities of each location with radius increasing for higher probabilities. These probabilities are the results of four methods on the same Dataset (LB 5s), with our proposed network DME-UNet (top left), the fully connected network used by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}  }\hspace{0pt}%DIFAUXCMD
FCNet (top right), the 3 states Hidden Markov Models HMM (bottom left), and the First Time Passage apporach FPT (bottom right)}}
  %DIFAUXCMD
%DIFDELCMD < \label{figure4b}
%DIFDELCMD < \end{figure}
%DIFDELCMD <

%DIFDELCMD < \newpage
%DIFDELCMD <

%DIFDELCMD < %%%
\paragraph{\DIFdel{Application to Gua\~nape dataset}}
%DIFAUXCMD
\addtocounter{paragraph}{-1}%DIFAUXCMD
\DIFdel{The use of deep networks trained on the dataset of Peruvian boobies from Pescadores Island on trajectories from birds from another colony (i.e. Gua\~nape) revealed once again the higher accuracy of deep learning based algorithms (see Figure 3) . Both FCNet and DME-UNet outperformed HMM and FPT in terms of AUC }\DIFdelend \DIFaddbegin \paragraph{\DIFadd{(b) Generalization performance of pre-trained networks}}
\DIFadd{Overall, all networks trained with data from Pescadores reported a AUC performance higher than 0.78 (resp. 0.56) when applied to Guañape (resp. Fernando de Noronha) dataset }\DIFaddend (\DIFaddbegin \DIFadd{Fig. \ref{figure_roc_projection}). AUC performance averaged 0.85 when using deep networks trained with the boobies dataset and 0.72 with cormorants data (see Tab. \ref{table_projection}). On both datasets, the best models were UNet and CNN  models trained from boobies data with respectively AUC scores of 0.98 and 0.87. In particular, they outperformed the HMM that were specifically fitted to Guañape and Fernando de Noronha data. By contrast, the FCNet used by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018} }\hspace{0pt}%DIFAUXCMD
that obtained better results than HMM on the Pescadores dataset (AUC of 0.89 vs 0.86 for HMM) did not predict better than HMM when used at Guañape (}\DIFaddend e.g. \DIFdelbegin \DIFdel{, with AUC of around 0.97 for neural networks vs . 0.88 }\DIFdelend \DIFaddbegin \DIFadd{AUC of 0.89 vs 0.92 }\DIFaddend for HMM). The \DIFdelbegin \DIFdel{Hellinger distance of }\DIFdelend \DIFaddbegin \DIFadd{MSE for }\DIFaddend the estimated dive distribution maps stressed the greater relevance of \DIFdelbegin \DIFdel{DME-UNet }\DIFdelend \DIFaddbegin \DIFadd{UNet }\DIFaddend predictions with a \DIFdelbegin \DIFdel{distance }\DIFdelend \DIFaddbegin \DIFadd{MSE }\DIFaddend value 1.6 times smaller than the one derived from \DIFdelbegin \DIFdel{FCNet estimations and 2 }\DIFdelend \DIFaddbegin \DIFadd{CNN estimations and 1.9 }\DIFaddend times smaller than the one derived from HMM \DIFdelbegin \DIFdel{estimation. }\DIFdelend \DIFaddbegin \DIFadd{estimations (Tab. \ref{table_projection}). As illustrated in Fig. \ref{figure_map_projection}, only the Unet did not overestimate the number of dives in the vicinity of the colony as well as an other foraging area southward from the colony.
}\DIFaddend

\begin{table}[h]
 \caption{\textbf{Deep Network Testing} - The deep networks fitted on the dataset from Pescadores have been used for dive prediction in Guañape and in Fernando de Noronha. Deep networks are described by their reference name (see Table \ref{table_training}). AUC is for area under the roc curve. BCE is the binary cross entropy. MSE corresponds to the mean square error of the diving distribution maps estimated with kernel density estimations and plotted in Figure \ref{figure_roc_projection} to the correct diving distribution. SV is for Peruvian boobies (\textit{Sula variegata)}}
  \centering
  \begin{tabular}{llllllll}
    \toprule
    Dataset  &  Resolution &  Model & AUC & BCE & F-score & MSE \\
    \midrule
    SV      & 5s  & FPT         & 0.65 & 0.57 & 0.43 & 10.9 \\
  (Guañape) &   & HMM         & 0.92 & 2.46 & 0.88 & 7.7  \\
            &     & SV\_FCNet\_5s & 0.89 & 0.31 & 0.80 & 7.7  \\
            &     & SV\_CNNet\_5s & 0.97 & 0.20 & 0.91 & 6.5  \\
            &     & {\bf SV\_UNet\_5s}  &  {\bf 0.98} &  {\bf 0.10} &  {\bf 0.91} & {\bf 4.0}  \\
            &     & LB\_FCNet\_5s & 0.78 & 0.09 & 0.05 & 13.8 \\
            &     & LB\_CNNet\_5s & 0.87 & 0.07 & 0.07 & 7.8 \\
            &     & LB\_UNet\_5s & 0.87 & 0.08 & 0.09 &14.5 \\
    \midrule
    SD      & 15s & FPT           & 0.50 & 0.75 & 0.22 & 7.5 \\
    (FdN)   &     & HMM           & 0.84 & 1.86 & 0.81 & 3.4  \\
            &     & SV\_FCNet\_15s  & 0.63 & 1.17 & 0.71 & 4.8  \\
            &     &  {\bf SV\_CNNet\_15s}  &  {\bf 0.87} &  {\bf 0.59} &  {\bf 0.83} & {\bf 3.8}  \\
            &     & SV\_UNet\_15s   & 0.73 & 0.58 & 0.55 & 5.8  \\
            &     & LB\_FCNet\_15s  & 0.56 & 0.61 & 0.48 & 6.5  \\
            &     & LB\_CNNet\_15s  & 0.62 & 0.27 & 0.08 & 12.9  \\
            &     & LB\_UNet\_15s   & 0.63 & 0.18 & 0.08 & 13.2  \\
    \bottomrule
  \end{tabular}
  \label{table_projection}
\end{table}

\begin{figure}[!h]
  \centering
  \DIFdelbeginFL %DIFDELCMD < \includegraphics[scale=0.5]{figure5.png}
%DIFDELCMD <   %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[scale=0.5]{figure_roc_projection.png}
  \DIFaddendFL \caption{\DIFdelbeginFL \textbf{\DIFdelFL{Maps of dive distributions of Peruvian Boobies from Gua\~nape Island}} %DIFAUXCMD
\DIFdelendFL \DIFaddbeginFL \textbf{\DIFaddFL{Performance of Tested Deep Networks}} \DIFaddendFL - \DIFdelbeginFL \DIFdelFL{These density maps were }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{ROC curves }\DIFaddendFL obtained \DIFdelbeginFL \DIFdelFL{through Kernel Density Estimation. The left map has been computed }\DIFdelendFL from \DIFdelbeginFL \DIFdelFL{true dives derived from TDR data. The four other maps are estimations }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the prediction }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL{this map}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{5 algorithms}\DIFaddendFL , \DIFdelbeginFL \DIFdelFL{using  all points of the trajectories with weights associated to diving probabilities estimated by the four studied approaches,  with our proposed network DME-UNet }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{First-Time Passage }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{top left}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{FPT}\DIFaddendFL ), \DIFdelbeginFL \DIFdelFL{the fully connected network used by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}  }\hspace{0pt}%DIFAUXCMD
FCNet (top right), the 3 states }\DIFdelendFL Hidden Markov Models \DIFaddbeginFL \DIFaddFL{(}\DIFaddendFL HMM\DIFaddbeginFL \DIFaddFL{), Fully-Connected Network }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{bottom left}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{FCNet}\DIFaddendFL ), \DIFaddbeginFL \DIFaddFL{Fully-Convolutional Network (CNNet) }\DIFaddendFL and \DIFaddbeginFL \DIFaddFL{U-Network (UNet) on 2 distinct test datasets. SV stands for Peruvian boobies (}\textit{\DIFaddFL{Sula variegata}}\DIFaddFL{), and LB stands for Guanay cormorants (}\textit{\DIFaddFL{Leucocarbo bougainvilli}}\DIFaddFL{). The deep networks used in this figure have been trained on }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL{First Time Passage apporach FPT }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{dataset from Pescadores }\DIFaddendFL (\DIFdelbeginFL \DIFdelFL{bottom right}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{see Fig. \ref{figure_roc_training} and Tab. \ref{table_training}}\DIFaddendFL ). \DIFdelbeginFL \DIFdelFL{Hellinger distance }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{They have been used for dive prediction }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL{the 4 estimations to the ground truth defined as the TRUE DIVES map are }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{Peruvian boobies }\DIFaddendFL in \DIFdelbeginFL \DIFdelFL{Table \ref{table3}}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{Guañape (left column) and for masked boobies in Fernando de Noronha (right column).}\DIFaddendFL }
  \DIFdelbeginFL %DIFDELCMD < \label{figure5}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{figure_roc_projection}
\DIFaddendFL \end{figure}

\DIFaddbegin \begin{figure}[!h]
  \centering
  \includegraphics[scale=0.5]{figure_map_projection.png}
  \caption{\textbf{\DIFaddFL{Maps of dive distributions of Peruvian Boobies from Guañape Island}} \DIFaddFL{- These density maps were obtained through Kernel Density Estimation. The top left map has been computed from true dives derived from TDR data. The five other maps are estimations of this map, using  all points of the trajectories with weights associated to diving probabilities estimated by the studied approaches:  First-Passage Time (FPT), Hidden Markov Model (HMM), Fully Connected Network used by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018}  }\hspace{0pt}%DIFAUXCMD
FCNet (top right), fully-Convolutional Network (CNNet), and the U-Network (UNet). Dive map mean square error (MSE) between estimated and reference distribution are in Table \ref{table_projection}}}
  \label{figure_map_projection}
\end{figure}


\paragraph{\DIFadd{(c) Network Fine-Tuning}}
\DIFadd{In this section, we evaluated the benefits of a fine-tuning strategy for the prediction of masked boobies dives. As expected, all deep networks initialized using previous models converged more quickly than deep networks trained from scratch. In particular, a dataset of 15 foraging trips (i.e. around 30k GPS positions) was enough for convolutional networks to obtain AUC of 0.9 using fine-tuning, whereas deep networks trained from scratch needed twice as many trips for the same predictive performance (Figure \ref{figure_fine_tuning}). The improvement issued from a fine-tuning was notably important for small-to-medium datasets (5-10 foraging trips, i.e. 10k to 20k GPS positions), and for the CNN. It decreased as the size of the dataset increased. From our experiments, at least 5 trips were necessary to fine-tune a relevant network compared with the HMM baseline (see for instance bottom-center in Fig. \ref{figure_fine_tuning}). The best neural network predictions for the Brazilian dataset are illustrated in Fig. \ref{figure_map_prediction}.
}

\begin{figure}[!h]
  \includegraphics[scale=0.55]{figure_fine_tuning.png}
  \caption{\textbf{\DIFaddFL{Fine-tuning}} \DIFaddFL{- AUC indices of trained deep network function of dataset size.}}
  \label{figure_fine_tuning}
\end{figure}


\DIFaddend \section{Discussion}
This study aimed at predicting seabirds dives from GPS data only \DIFdelbegin \DIFdel{by training a deep network in a supersized }\DIFdelend \DIFaddbegin \DIFadd{using deep neural networks trained in a supervised }\DIFaddend manner based on TDR data to define the \DIFdelbegin \DIFdel{true }\DIFdelend \DIFaddbegin \DIFadd{groundtruthed }\DIFaddend dives. In line with \cite{browning_predicting_2018}, this study further supports the relevance of deep learning approach over classical methods for dive predictions. \DIFdelbegin \DIFdel{Moreover, we introduce a new deep network, the so-called DME-UNet, which combines a state-of-the-art deep network architecture with a meaningful geometrical representation of trajectory data. We }\DIFdelend \DIFaddbegin \DIFadd{Using convolutional architectures rather fully-connected ones, we }\DIFaddend reported even better results with higher stability to the different data inputs\DIFaddbegin \DIFadd{, as well as better generalization abilities}\DIFaddend .

\DIFdelbegin \DIFdel{The proposed network allows not only to better predict dive behaviour but also results }\DIFdelend \DIFaddbegin \DIFadd{Peruvian boobies and Guanay cormorants tracked in Peru breed in a highly productive upwelling system, the Humboldt Current System (HCS) and feed on the same preys, i.e. Peruvian anchovies \mbox{%DIFAUXCMD
\cite{jahncke_diets_1998}}\hspace{0pt}%DIFAUXCMD
. However, they are known to have distinct foraging strategies: boobies are plunge divers reaching in average about 2 m depth and spending most of the time in fly, while cormorants dive deeper and longer on average, reach up to 30 m depth, and spend up to 40\% of the time resting on the water surface \mbox{%DIFAUXCMD
\cite{weimerskirch_foraging_2012} }\hspace{0pt}%DIFAUXCMD
(Tab. \ref{table_data}). By contrast masked boobies breeding at Fernando de Noronha are plunge divers similarly to Peruvian boobies, yet they forage mainly in oligotrophic waters \mbox{%DIFAUXCMD
\cite{de_santana_campelo_zooplankton_2019} }\hspace{0pt}%DIFAUXCMD
and feed mainly on flying fish and flying squids \mbox{%DIFAUXCMD
\cite{nelson_pelicans_2005,mancini_role_2014}}\hspace{0pt}%DIFAUXCMD
. Their foraging strategies then differ from Peruvian boobies as they perform longest trips and spend more time resting at sea surface (Tab. \ref{table_data}). We demonstrated that for these three species, our best deep network models were able to accurately predict around 95\% of dives and outperformed HMM that predicted around 85\% of dives. In particular, the proposed U-shape deep network (UNet) demonstrated a greater robustness to different data inputs, as it obtained the best results whatever the sampling resolution (Tab.\ref{figure_roc_training}).
}

\DIFadd{Additionally, UNet also resulted }\DIFaddend in better seabird dive distribution maps \DIFdelbegin \DIFdel{. }\DIFdelend \DIFaddbegin \DIFadd{(Fig. \ref{figure_map_projection}). }\DIFaddend Recently numerous studies used seabirds dive as a proxy for prey distribution, and such distribution are usually computed by applying KDE on dive predictions derived from HMMs \cite{delord_movements_2020,weimerskirch_at-sea_2020,zhang_gps_2019}. Here, we show that the error in the estimation of dive distributions maps can be \DIFdelbegin \DIFdel{divised }\DIFdelend \DIFaddbegin \DIFadd{divided }\DIFaddend by two by using deep learning tools rather than HMM tools. In our specific study, HMMs \DIFdelbegin \DIFdel{have }\DIFdelend over-estimated the frequency of dives at \DIFdelbegin \DIFdel{proximity of breeding locations }\DIFdelend \DIFaddbegin \DIFadd{specific locations (including the vicinity of the colony)}\DIFaddend . Sulids and cormorants spend time bathing near their breeding territories involving vigorous splashing and beating the water with the wings \DIFdelbegin \DIFdel{, }\DIFdelend \cite{nelson_pelicans_2005}. Such behaviours associated to low speed might be erroneously classified as diving behaviour by \DIFdelbegin \DIFdel{HMMs }\DIFdelend \DIFaddbegin \DIFadd{state-of-the-art tools }\DIFaddend which could explain the observed bias. \DIFdelbegin \DIFdel{For the same reason, we might explain that }\DIFdelend \DIFaddbegin \DIFadd{This might also explain why }\DIFaddend HMM are better \DIFdelbegin \DIFdel{on the boobiesdataset than with cormorants}\DIFdelend \DIFaddbegin \DIFadd{at predicting boobies' than cormorants' dives }\DIFaddend because these birds spend more time resting at the surface, which corresponds to low \DIFdelbegin \DIFdel{speeds }\DIFdelend \DIFaddbegin \DIFadd{speed patterns }\DIFaddend without being dives (see Table \DIFdelbegin \DIFdel{\ref{table1}). The high BCE obtained by HMM also suggests that in these situations HMM predicts erroneously dive with high confidence. In opposition, deep learning seem better for discriminating such }\DIFdelend \DIFaddbegin \DIFadd{\ref{table_data}). We may also stress that Cormorants trajectories are characterized by relatively long gaps in the regularly sampled sequence of locations, since these devices do not receive a satellite signal while submerged \mbox{%DIFAUXCMD
\cite{boyd_movement_2014,wilson_technological_2012}}\hspace{0pt}%DIFAUXCMD
. This may in turn make more complex the analysis of Cormorants trajectories. In this respect, UNet showed a greater ability to  discriminate the }\DIFaddend resting/bathing behaviours from dives\DIFdelbegin \DIFdel{. It would be nice to see further why and how deep networks succeed in outperforming HMMs, but the interpretation is one of the inherent difficulty  of deep learning. Not that it is not possible, but that it would require further analysis.Yet, having such results on deep networks performance over HMM is a first step in the demonstration that there is some information that the HMMs misses and that it can be captured by deep networks. }%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{, and a greater robustness to the presence of linearly-interpolated segments. Whereas HMM are mostly driven by fine-scale features (w.r.t. the considered time resolution), UNets exploit a multi-scale analysis of trajectory data and can extract relevant multi-scale information to retrieve dive. Future work could investigate further the key features extracted by UNets. }\DIFaddend As shown in Figure \DIFdelbegin \DIFdel{\ref{figure1}, the better performance reported with DME-UNet }\DIFdelend \DIFaddbegin \DIFadd{\ref{figure_roc_training}, the performance of the deep networks was }\DIFaddend closely related to the temporal resolution of the sampled dataset. \DIFdelbegin \DIFdel{In particular, from Peruvian boobies' trajectories resampled at 15s and 30s, similar results were obtained through DME-UNet and HMM . However, we observed that with the 5s resolution dataset, deep networks had outperformed HMM. This suggests that HMMs are great approaches to trajectory segmentation with relatively large temporal resolution, and that they are unable to interpret movement process at very fine spatio-temporal scales }\DIFdelend \DIFaddbegin \DIFadd{Whereas HMM did not succeed in exploiting higher-resolution data, UNets led to better performance when the resolution increased. This supports a greater ability of UNets both to deal with potential aliasing effects }\DIFaddend as well as \DIFdelbegin \DIFdel{deep networks do. Knowing that Peruvian boobies dive during very short periods, approximately 2 seconds (see Table \ref{table1}), this suggests that the deep networks would be able to capture diving behavioural movements from a GPS track sampled with a resolution in the same order of magnitude than dive durations. For the Guanay cormorants dataset, DME-UNet had better results than HMM for all tested sampling resolution. However, cormorants dives last about 20s, which could explain why even with the 30s sampled dataset deep networks had better results than HMMs. We might infer that a decrease of the performance of deep networks would occur for sampling resolution of 1 minute or more.
}\DIFdelend \DIFaddbegin \DIFadd{to exploit fine-scale features. }\DIFaddend With technological advances in sensor technology, ecologists are able to collect larger amount of data than ever before. We might expect GPS with lower consumption \DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{and }\DIFaddend higher resolution in the future. Such an expected trend would make more critical the exploitation of \DIFdelbegin \DIFdel{development of }\DIFdelend the proposed deep learning approaches to make the most of the collected high-resolution  animal trajectories   \cite{beyan_setting_2020,malde_machine_2020, yoda_advances_2019}\DIFaddbegin \DIFadd{.
}\DIFaddend

\DIFdelbegin \DIFdel{The GPS tracks were characterized by short gaps in the regularly sampled sequence of locations, since these devices do not receive a satellite signal while submerged \mbox{%DIFAUXCMD
\cite{boyd_movement_2014,wilson_technological_2012}}\hspace{0pt}%DIFAUXCMD
.
These gaps are therefore sometimes directly considered indicative of diving behaviour \mbox{%DIFAUXCMD
\cite{weimerskirch_foraging_2012}}\hspace{0pt}%DIFAUXCMD
.
Surprisingly, HMM did not take benefits from such variable for inferring dives.
Nevertheless, the use of this coverage information as input helped substantially deep networks to predict dives.
Indeed, without coverage data, the FCNet proposed by \mbox{%DIFAUXCMD
\cite{browning_predicting_2018} }\hspace{0pt}%DIFAUXCMD
predicted dives with relatively low accuracy, with in particular AUC of 0.71 which is low  compared to HMMs' performance (AUC of 0.87), while it obtained AUC of 0.94 using this external information (see Figure \ref{figure2}). In their study, Browning et al. also used in some cases altitude data to get better performance than HMM. One could therefore argue that deep networks are not relevant with longitude and latitude data only.
However, the DME-UNet proposed in this study demonstrated the ability of deep networks to classify animal behaviours in such situation. Indeed, without the coverage ratio variable it obtained still an AUC of 0.92 which was about 5 \% more than HMM. This demonstrates that this approach is not only relevant for seabirds where coverage ratio is an important external variable, but also for any trajectory dataset.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdel{A key breakthrough of our approach was thus to use what we called a Distance Matrix Encoder (DME), which is a simple neural network block which aims to extract features for a better geometrical description of a trajectory.
The performance of machine learning methods is heavily dependent on the choice of data representation (or features) on which they are applied \mbox{%DIFAUXCMD
\cite{bengio_representation_2014}}\hspace{0pt}%DIFAUXCMD
.
Most studies dealing with trajectory data represented movement with longitude and latitude time-series. Yet, some studies argued that such representation might not be relevant for neural-network based methods since movement trajectories inherently contain 2D spatial information which might not be easily perceivable in simple time-series. For instance, previous works  investigated one-hot representations initially introduced for text data  \mbox{%DIFAUXCMD
\cite{nguyen_geotracknet-maritime_2021} }\hspace{0pt}%DIFAUXCMD
as well as trajectory image \mbox{%DIFAUXCMD
\cite{endo_classifying_2016}}\hspace{0pt}%DIFAUXCMD
. Here, we explored distance matrix representations as the distance matrix of positions has been shown to capture relevant spatial information for protein structure prediction \mbox{%DIFAUXCMD
\cite{senior_improved_2020, xu_analysis_2019}}\hspace{0pt}%DIFAUXCMD
. Our study  demonstrates its relevance when considered as input to a neural network architecture to complement longitude and latitude time series. Future work may further investigate how distance matrix representation could be of interest for other deep learning approaches to trajectory data, including among others Recurrent Neural Network (RNN), and Generative Adversarial Networks (GAN) for trajectory prediction and simulation \mbox{%DIFAUXCMD
\cite{ardakani_encoding_2017,goodfellow_generative_2014,isola_image--image_2018,rew_animal_2019}}\hspace{0pt}%DIFAUXCMD
.
}%DIFDELCMD <

%DIFDELCMD < %%%
\DIFdel{When considering learning-based schemes, the assessment of the generalization performance is of key importance}\DIFdelend \DIFaddbegin \DIFadd{When considering neural network approaches, training models which may apply beyond the considered training framework is a key feature, generally referred to as the generalization performance of the trained neural networks}\DIFaddend . Beyond the evaluation of dive prediction performance on a trajectory dataset, which is independent from the training dataset, the question whether a model trained on a given dataset, e.g. for a given species, colony and time period, may apply to other species, colonies and/or time periods, naturally arises as a key question. Numerous studies in the deep learning literature \cite{kawaguchi_generalization_2020,zhang_understanding_2017} have highlighted that some neural architectures show relevant generalization properties whereas others may not. Here, we evaluated the generalization performance of the \DIFdelbegin \DIFdel{benchmarked methods for two colonies of Peruvian boobies. }\DIFdelend \DIFaddbegin \DIFadd{three benchmarked deep networks.
}

\DIFadd{Thus we demonstrate the ability of deep networks trained at a colony for one species to also apply to an another colony (of the same ecosystem) for the same species. In our example, }\DIFaddend Peruvian boobies from \DIFdelbegin \DIFdel{Gua\~nape }\DIFdelend \DIFaddbegin \DIFadd{Guañape }\DIFaddend Island did have different foraging strategies from their counterparts from Pescadores island, with trips two times longer and dives slightly longer (see Table \DIFdelbegin \DIFdel{\ref{table1}). It turned out that the two deep networks were very stable on this testing dataset predicting dives with high accuracy (AUC of 0.97}\DIFdelend \DIFaddbegin \DIFadd{\ref{table_data}). However, the UNet reached similar dive prediction performance when applied to Guañape data. This suggests that dive patterns are highly similar between Peruvian boobies from both colonies. We also show the great ability of the CNN to generalize dive prediction to a seabird of same genus but from a totally distinct ecosystem. When applied to masked boobies trajectories from a Brazilian colony the CNN trained from Peruvian boobies data obtained an AUC of 0.87 despite the important difference in foraging strategies (Tab. \ref{table_projection}}\DIFaddend ). The \DIFdelbegin \DIFdel{improvement of neural networks over the HMM fitted to the dataset was about 10\%}\DIFdelend \DIFaddbegin \DIFadd{same model trained on masked boobies data reached an AUC of 0.93 (Fig. \ref{figure_fine_tuning}), suggesting that diving characteristics are slightly different. Masked boobies from the Brazilian colony feed indeed on different preys, and spend way more time resting at the surface (Tab.\ref{table_data}). As deep networks trained on cormorants unsurprisingly led to less accurate prediction when used to predict boobies dives, we suggest that the CNN may capture genus-specific features}\DIFaddend . These results \DIFaddbegin \DIFadd{then }\DIFaddend support the relevance of deep learning schemes as 'ready-to-use' tools which could be used by ecologists to predict seabirds dives on new \DIFdelbegin \DIFdel{datasets}\DIFdelend \DIFaddbegin \DIFadd{(small) datasets, including when these datasets do not include groundtruthed dive data for a supervised training}\DIFaddend . To make easier such applications, we share online the different models we \DIFdelbegin \DIFdel{pre-trained }\DIFdelend \DIFaddbegin \DIFadd{trained }\DIFaddend on the considered \DIFdelbegin \DIFdel{dataset }\DIFdelend \DIFaddbegin \DIFadd{datasets }\DIFaddend (https://github.com/AmedeeRoy/BirdDL/\DIFdelbegin \DIFdel{results).
}\DIFdelend \DIFaddbegin \DIFadd{models).
}

\DIFaddend Beyond such a direct application, trained models \DIFdelbegin \DIFdel{may also be }\DIFdelend \DIFaddbegin \DIFadd{are also }\DIFaddend of key interest to explore transfer learning strategies, which refer to the ability of exploiting some previously trained models to address a new task or dataset rather than training a new model from scratch. \DIFdelbegin \DIFdel{Fine tuning is a typical example of transfer learning procedure. It uses a previously trained model as the initialization of the training scheme. Such a strategy may be }\DIFdelend \DIFaddbegin \DIFadd{We illustrated how fine-tuned CNN and UNet models could outperform HMM with smaller training datasets. For instance, the fine-tuned CNN for the prediction of masked boobies' dive was able to converge and outperform HMM with a dataset twice as small as the dataset required to reach same performance without fine-tuning (Fig. \ref{figure_fine_tuning}). Such a result was even possible by initializing neural networks with the model trained with cormorant data. This further supports the ability of deep networks to generalize their prediction from deep diving seabirds (e.g. cormorants) to plunge divers (e.g. boobies). Fine-tuning is thus }\DIFaddend particularly relevant when the training dataset may not be sufficiently large to train a model from scratch. \DIFdelbegin \DIFdel{We then expect the models trained in this work to be potentially of interest for the }\DIFdelend \DIFaddbegin \DIFadd{While the need of large dataset is often presented as a drawback for supervized techniques, we demonstrated that relatively small datasets (5-10 foraging trips, i.e. 10k to 20k GPS data) may be enough to fine-tune deep networks and outperform stat-of-the-art approach to data segmentation. Thus, we expect that our models will be of interest for future work on seabird trajectory segmentation, as they could be used as initializations for }\DIFaddend fine-tuning \DIFdelbegin \DIFdel{of these models on datasets referring to other colonies and species of same genus}\DIFdelend \DIFaddbegin \DIFadd{procedures}\DIFaddend .

\subsection*{Acknowledgements}
We thank all people involved in fieldworks: H. Weimerskirch, K. Delord, C. Barbraud, Y. Tremblay, J. Silva, G. Passuni, C. Boyd\DIFdelbegin \DIFdel{and }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend C. Saraux\DIFdelbegin \DIFdel{. }\DIFdelend \DIFaddbegin \DIFadd{, A. Brunel, J.Jacoby, L. Figuereido and G. T. Nunes. }\DIFaddend We thank Proabonos for permission to work on \DIFdelbegin \DIFdel{Isla Gua\~nape  and Isla Pescadores .
}\DIFdelend \DIFaddbegin \DIFadd{Guañape and Pescadores Islands. We thank the Brazilian Ministry of Environment (ICMBio) and Fernando de Noronha's firemen for the authorization and logistical support to fieldworks in Brazil.
}\DIFaddend

\subsection*{Funding statement}
This work is a contribution to the TRIATLAS project (European Union's Horizon 2020 research and innovation program – grant agreement No. 817578), and to the Young Team IRD Programm (JEAI)  \DIFdelbegin \DIFdel{for }\DIFdelend TABASCO project. RF was supported by LEFE program (LEFE MANU project IA-OAC), CNES (grant SWOT-DIEGO) and ANR Projects Melody and OceaniX. Fieldworks have been conducted thanks to the cooperative agreement between IRD, the Agence Nationale de la Recherche (ANR) project TOPINEME, and of the International Joint Laboratory DISCOH.

\subsection*{Ethics statement}
Foraging trip routes and dive depth data were obtained from electronic devices attached to Peruvian \DIFdelbegin \DIFdel{Boobies and Guanay Cormorants }\DIFdelend \DIFaddbegin \DIFadd{boobies and Guanay cormorants }\DIFaddend tagged at the Pescadores \DIFdelbegin \DIFdel{Gua\~nape }\DIFdelend \DIFaddbegin \DIFadd{and Guañape }\DIFaddend Islands, Peru, from 2007 to \DIFdelbegin \DIFdel{2013. Capture, restraint, holding and release of birds for attachment and subsequent removal of electronic devices were performed under the auspices of institutional animal use and care a }\DIFdelend \DIFaddbegin \DIFadd{2013, and from masked boobies tagged at the Fernando de Noronha, Brazil, from 2017 to 2019. This work was conducted with the approval of the }\DIFaddend Peruvian federal agency, Programa de Desarrollo Productivo Agrario Rural, commonly known as “Agrorural”. Headquarters of Agrorural are located at Av. Salaverry 1388, Lima, Peru\DIFdelbegin \DIFdel{. Protocols for care and use of subject birds were reviewed and approved by Agrorural officials prior to every fieldwork sessions}\DIFdelend \DIFaddbegin \DIFadd{, and of the Brazilian Ministry of Environment—Instituto Chico Mendes de Conservação da Biodiversidade (Authorization No 52583-5)}\DIFaddend .

\printbibliography

\newpage

\end{document}
